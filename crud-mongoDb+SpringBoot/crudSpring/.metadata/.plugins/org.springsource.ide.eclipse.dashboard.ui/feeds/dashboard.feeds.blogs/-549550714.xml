<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Spring</title>
  <link rel="alternate" href="https://spring.io/blog" />
  <link rel="self" href="https://spring.io/blog.atom" />
  <id>http://spring.io/blog.atom</id>
  <icon>https://spring.io/favicon.ico</icon>
  <updated>2021-02-16T19:23:00Z</updated>
  <entry>
    <title>This Week in Spring - February 16th, 2021</title>
    <link rel="alternate" href="https://spring.io/blog/2021/02/16/this-week-in-spring-february-16th-2021" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>Josh Long</name>
    </author>
    <id>tag:spring.io,2021-02-16:4364</id>
    <updated>2021-02-16T19:23:00Z</updated>
    <content type="html">&lt;p&gt;Hi, Spring fans! Welcome to another installment of &lt;em&gt;This Week in Spring&lt;/em&gt;! This week is fixing to be a really fun one! &lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ll be speaking at the &lt;a href="https://www.meetup.com/seajug/events/276135388/"&gt;&lt;strong&gt;Seattle JUG&lt;/strong&gt; tonight&lt;/a&gt;. It&amp;rsquo;s free, online, virtual, etc. Join us, won&amp;rsquo;t you? &lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ll also be speaking at the legendary &lt;a href="http://DevNexus.com"&gt;&lt;strong&gt;Devnexus&lt;/strong&gt;&lt;/a&gt; event this week. Do &lt;em&gt;not&lt;/em&gt; miss that. Or the show. It&amp;rsquo;s free, being held virtually, online, and a &lt;em&gt;ton of us&lt;/em&gt; from the Spring team will be there. &lt;/p&gt;
&lt;p&gt;We&amp;rsquo;ve got a lot of good stuff to get to this week so let&amp;rsquo;s dive in!&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;My buddy, the amazing and inestimable, Tanzu observability engineer Tommy Ludwig, and I wrote a little blog, &lt;a href="https://spring.io/blog/2021/02/09/metrics-and-tracing-better-together"&gt;&lt;em&gt;Metrics and Tracing: Better Together&lt;/em&gt;&lt;/a&gt;. It&amp;rsquo;s chock full of Tommy&amp;rsquo;s brilliance and my terrible terrible puns. Don&amp;rsquo;t miss it!&lt;/li&gt;
  &lt;li&gt;In last week&amp;rsquo;s installment of &lt;a href="https://spring.io/blog/2021/02/11/a-bootiful-podcast-doordash-tech-lead-manager-zohaib-sibte-hassan-on-spring-boot-kotlin-grpc-and-more"&gt;&lt;em&gt;A Bootiful Podcast&lt;/em&gt;, I talked to Doordash tech lead manager Zohaib Sibte Hassan on Spring Boot, Kotlin, GRPC, and more&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://blogs.vmware.com/opensource/2021/02/09/an-open-source-approach-to-decentralized-transactions/"&gt;An Open Source Approach to Decentralized Transactions&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;This looks cool: a way to &lt;a href="https://twitter.com/serceman/status/1359477990501937156?s=12"&gt;inspect RSocket frames from within Chrome&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://blogs.vmware.com/opensource/2021/02/11/musings-on-supply-chain-security/"&gt;Musings on Supply Chain Security&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://tanzu.vmware.com/modern-apps"&gt;Paving the Road to Modern Apps, by VMware Tanzu&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://rieckpil.de/testing-spring-boot-applications-masterclass/"&gt;Philip Riecks has an interesting new tutorial, &lt;em&gt;Testing Spring Boot Applications Masterclass&lt;/em&gt;, for sale.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2021/02/11/spring-authorization-server-0-1-0-available-now"&gt;Spring Authorization Server 0.1.0 available now&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2021/02/11/spring-cloud-hoxton-sr10-has-been-released"&gt;Spring Cloud Hoxton.SR10 has been released&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2021/02/16/spring-framework-5-3-4-and-5-2-13-available-now"&gt;Spring Framework 5.3.4 and 5.2.13 available now&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2021/02/11/spring-security-5-4-4-5-3-8-and-5-2-9-released"&gt;Spring Security 5.4.4, 5.3.8, and 5.2.9 released&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2021/02/16/spring-vault-2-3-1-available"&gt;Spring Vault 2.3.1 available&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://twitter.com/VMware/status/1360490905782931456"&gt;Mark your calendar for these 2021 VMware conferences - SpringOne, VMworld, CloudLIVE, Connect. &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>Spring Vault 2.3.1 available</title>
    <link rel="alternate" href="https://spring.io/blog/2021/02/16/spring-vault-2-3-1-available" />
    <category term="releases" label="Releases" />
    <author>
      <name>Mark Paluch</name>
    </author>
    <id>tag:spring.io,2021-02-16:4363</id>
    <updated>2021-02-16T15:18:00Z</updated>
    <content type="html">&lt;div class="paragraph"&gt;
&lt;p&gt;On behalf of the community, I&amp;#8217;d like to announce the availability of the Spring Vault service release &lt;code&gt;2.3.1&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;This release ships with mostly bugfixes, dependency upgrades, and selected features.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;For a complete list of changes, see the &lt;a href="https://github.com/spring-projects/spring-vault/releases/tag/2.3.1"&gt;2.3.1 changelog&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&lt;a href="http://projects.spring.io/spring-vault/"&gt;Project Page&lt;/a&gt; | &lt;a href="https://github.com/spring-projects/spring-vault"&gt;GitHub&lt;/a&gt; | &lt;a href="https://github.com/spring-projects/spring-vault/issues"&gt;Issues&lt;/a&gt; | &lt;a href="https://github.com/spring-projects/spring-vault/releases/tag/2.3.1"&gt;Release &lt;code&gt;2.3.1&lt;/code&gt; on GitHub&lt;/a&gt; | &lt;a href="http://docs.spring.io/spring-vault/docs/2.3.1/reference/html/"&gt;Documentation for &lt;code&gt;2.3.1&lt;/code&gt;&lt;/a&gt; | &lt;a href="http://stackoverflow.com/questions/tagged/spring-vault"&gt;Stack Overflow&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>Spring Framework 5.3.4 and 5.2.13 available now</title>
    <link rel="alternate" href="https://spring.io/blog/2021/02/16/spring-framework-5-3-4-and-5-2-13-available-now" />
    <category term="releases" label="Releases" />
    <author>
      <name>St√©phane Nicoll</name>
    </author>
    <id>tag:spring.io,2021-02-16:4362</id>
    <updated>2021-02-16T12:07:00Z</updated>
    <content type="html">&lt;p&gt;On behalf of the team and everyone who has contributed, I am pleased to announce that Spring Framework &lt;code&gt;5.3.4&lt;/code&gt; and &lt;code&gt;5.2.13&lt;/code&gt; are available now.&lt;/p&gt;
&lt;p&gt;Spring Framework &lt;code&gt;5.3.4&lt;/code&gt; includes &lt;a href="https://github.com/spring-projects/spring-framework/releases/tag/v5.3.4"&gt;62 fixes and improvements&lt;/a&gt;. Spring Framework &lt;code&gt;5.2.13&lt;/code&gt; includes &lt;a href="https://github.com/spring-projects/spring-framework/releases/tag/v5.2.13.RELEASE"&gt;18 selected fixes and improvements&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Stay tuned for follow-up Spring Boot releases later this week.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://projects.spring.io/spring-framework/"&gt;Project Page&lt;/a&gt; | &lt;a href="https://github.com/spring-projects/spring-framework"&gt;GitHub&lt;/a&gt; | &lt;a href="https://github.com/spring-projects/spring-framework/issues"&gt;Issues&lt;/a&gt; | &lt;a href="https://docs.spring.io/spring-framework/docs/5.3.4/spring-framework-reference"&gt;Documentation&lt;/a&gt;&lt;/p&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>Spring Authorization Server 0.1.0 available now</title>
    <link rel="alternate" href="https://spring.io/blog/2021/02/11/spring-authorization-server-0-1-0-available-now" />
    <category term="releases" label="Releases" />
    <author>
      <name>Joe Grandja</name>
    </author>
    <id>tag:spring.io,2021-02-12:4361</id>
    <updated>2021-02-12T03:23:00Z</updated>
    <content type="html">&lt;div class="paragraph"&gt;
&lt;p&gt;On behalf of the team and everyone who has contributed, it is my pleasure to announce the general availability of Spring Authorization Server 0.1.0.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;You can download it from &lt;a href="https://repo.spring.io/release/"&gt;repo.spring.io&lt;/a&gt; and Maven Central by using the module coordinates:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code data-lang="groovy"&gt;compile 'org.springframework.security.experimental:spring-security-oauth2-authorization-server:0.1.0'&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;For additional details on this new project, see the &lt;a href="https://spring.io/blog/2020/04/15/announcing-the-spring-authorization-server"&gt;initial announcement&lt;/a&gt; and &lt;a href="https://github.com/spring-projects-experimental/spring-authorization-server"&gt;project page&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The main features delivered in this release are:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;OpenID Connect Core 1.0&amp;#8201;&amp;#8212;&amp;#8201;&lt;a href="https://openid.net/specs/openid-connect-core-1_0.html#CodeFlowAuth"&gt;Authorization Code Flow&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;OpenID Connect Discovery 1.0&amp;#8201;&amp;#8212;&amp;#8201;&lt;a href="https://openid.net/specs/openid-connect-discovery-1_0.html#ProviderConfig"&gt;OpenID Provider Configuration&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;JSON Web Token (JWT) headers and claims customizer&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;See the &lt;a href="https://github.com/spring-projects-experimental/spring-authorization-server/releases/tag/0.1.0"&gt;release notes&lt;/a&gt; for complete details.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;To get started using Spring Authorization Server, see the &lt;a href="https://github.com/spring-projects-experimental/spring-authorization-server/tree/master/samples/boot/oauth2-integration"&gt;sample&lt;/a&gt; to become familiar with setup and configuration.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;We would love to gather your feedback as we strive to improve and build upon this release.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&lt;a href="https://github.com/spring-projects-experimental/spring-authorization-server"&gt;Project Page&lt;/a&gt; | &lt;a href="https://github.com/spring-projects-experimental/spring-authorization-server/issues"&gt;GitHub Issues&lt;/a&gt; |  &lt;a href="https://app.zenhub.com/workspaces/authorization-server-5e8f3182b5e8f5841bfc4902/board?repos=248032165"&gt;ZenHub Board&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>Spring Security 5.4.4, 5.3.8, and 5.2.9 released</title>
    <link rel="alternate" href="https://spring.io/blog/2021/02/11/spring-security-5-4-4-5-3-8-and-5-2-9-released" />
    <category term="releases" label="Releases" />
    <author>
      <name>Rob Winch</name>
    </author>
    <id>tag:spring.io,2021-02-12:4360</id>
    <updated>2021-02-12T02:04:00Z</updated>
    <content type="html">&lt;div class="paragraph"&gt;
&lt;p&gt;On behalf of the community, I&amp;#8217;m pleased to announce the release of Spring Security 5.4.4 (&lt;a href="https://github.com/spring-projects/spring-security/releases/tag/5.4.4"&gt;release notes&lt;/a&gt;), 5.3.8 (&lt;a href="https://github.com/spring-projects/spring-security/releases/tag/5.3.8.RELEASE"&gt;release notes&lt;/a&gt;), and 5.2.9 (&lt;a href="https://github.com/spring-projects/spring-security/releases/tag/5.2.9.RELEASE"&gt;release notes&lt;/a&gt;). These releases deliver bug fixes along with some minor improvements. Users are encouraged to update to the latest patch release.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&lt;a href="http://projects.spring.io/spring-security/"&gt;Project Site&lt;/a&gt; | &lt;a href="http://docs.spring.io/spring-security/site/docs/current/reference/htmlsingle/"&gt;Reference&lt;/a&gt; | &lt;a href="http://stackoverflow.com/questions/tagged/spring-security"&gt;Help&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: There was an issue releasing 5.4.3 and 5.3.7 which caused us to need to release 5.4.4 and 5.3.8.&lt;/p&gt;
&lt;/div&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>A Bootiful Podcast: Doordash tech lead manager Zohaib Sibte Hassan on Spring Boot, Kotlin, GRPC, and more</title>
    <link rel="alternate" href="https://spring.io/blog/2021/02/11/a-bootiful-podcast-doordash-tech-lead-manager-zohaib-sibte-hassan-on-spring-boot-kotlin-grpc-and-more" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>Josh Long</name>
    </author>
    <id>tag:spring.io,2021-02-12:4359</id>
    <updated>2021-02-12T01:07:00Z</updated>
    <content type="html">&lt;iframe title="Doordash tech lead manager Zohaib Sibte Hassan on Spring Boot, Kotlin, GRPC, and more" height="122" width="100%" style="border: none;" scrolling="no" data-name="pb-iframe-player" src="https://www.podbean.com/media/player/irvrk-fa794b?from=pb6admin&amp;download=1&amp;version=1&amp;auto=0&amp;share=1&amp;download=1&amp;rtl=0&amp;fonts=Helvetica&amp;skin=1&amp;pfauth=&amp;btn-skin=107"&gt;&lt;/iframe&gt;
&lt;p&gt;Hi, Spring fans! In this episode, &lt;a href="http://twitter.com/starbuxman"&gt;Josh Long (@starbuxman)&lt;/a&gt; talks to Doordash tech lead manager &lt;a href="http://twitter.com/zohaibility"&gt;Zohaib Sibte Hassan (@zohaibility)&lt;/a&gt; about Spring Boot, Kotlin, GRPC, organizational scalability, and more at Doordash.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;the &lt;a href="https://doordash.engineering/"&gt;Doordash Engineering blog&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://github.com/LogNet/grpc-spring-boot-starter"&gt;A GRPC Spring Boot Starter&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;the Gitter &lt;a href="https://gitter.im/R2DBC/r2dbc"&gt;chat for R2DBC&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.linkedin.com/in/zohaibsibtehassan/"&gt;Zohaib on LinkedIn&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>Spring Cloud Hoxton.SR10 has been released</title>
    <link rel="alternate" href="https://spring.io/blog/2021/02/11/spring-cloud-hoxton-sr10-has-been-released" />
    <category term="releases" label="Releases" />
    <author>
      <name>Olga Maciaszek-Sharma</name>
    </author>
    <id>tag:spring.io,2021-02-11:4358</id>
    <updated>2021-02-11T16:37:00Z</updated>
    <content type="html">&lt;p&gt;On behalf of the community, I am pleased to announce that the Service Release 10 (SR10) of the &lt;a href="https://cloud.spring.io"&gt;Spring Cloud Hoxton&lt;/a&gt; Release Train is available today. The release can be found in &lt;a href="https://repo1.maven.org/maven2/org/springframework/cloud/spring-cloud-dependencies/Hoxton.SR10/"&gt;Maven Central&lt;/a&gt;. You can check out the Hoxton &lt;a href="https://github.com/spring-projects/spring-cloud/wiki/Spring-Cloud-Hoxton-Release-Notes"&gt;release notes for more information&lt;/a&gt;.&lt;/p&gt;&lt;h2&gt;&lt;a href="#notable-changes-in-the-hoxton-release-train" class="anchor" name="notable-changes-in-the-hoxton-release-train"&gt;&lt;/a&gt;Notable Changes in the Hoxton Release Train&lt;/h2&gt;
&lt;p&gt;See all issues included in this release &lt;a href="https://github.com/orgs/spring-cloud/projects/47"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This was primarily a bug fix and documentation release. Hoxton.SR10 is compatible with Spring Boot 2.3.x and 2.2.x.&lt;/p&gt;&lt;h3&gt;&lt;a href="#fix-for-cve-2021-22113" class="anchor" name="fix-for-cve-2021-22113"&gt;&lt;/a&gt;Fix for CVE-2021-22113&lt;/h3&gt;
&lt;p&gt;This release contains the fix for CVE-2021-22113. Please find the report &lt;a href="https://tanzu.vmware.com/security/cve-2021-22113"&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;h3&gt;&lt;a href="#spring-cloud-commons" class="anchor" name="spring-cloud-commons"&gt;&lt;/a&gt;Spring Cloud Commons&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href="https://github.com/spring-cloud/spring-cloud-commons/issues/688"&gt;Random algorithm added for Spring Cloud LoadBalancer&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://github.com/spring-cloud/spring-cloud-commons/issues/689"&gt;Sticky implementation added for Spring Cloud LoadBalancer&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://github.com/spring-cloud/spring-cloud-commons/issues/856"&gt;Backported standalone &lt;code&gt;RetryableLoadBalancerExchangeFilterFunction&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Added the possibility to &lt;a href="https://github.com/spring-cloud/spring-cloud-commons/pull/855"&gt;refetch the instances for health-check&lt;/a&gt; in Spring Cloud LoadBalancer&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;&lt;a href="#spring-cloud-netflix" class="anchor" name="spring-cloud-netflix"&gt;&lt;/a&gt;Spring Cloud Netflix&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Fixed CVE-2021-22113&lt;/li&gt;
  &lt;li&gt;Several dependencies upgraded&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;&lt;a href="#spring-cloud-openfeign" class="anchor" name="spring-cloud-openfeign"&gt;&lt;/a&gt;Spring Cloud OpenFeign&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href="https://github.com/spring-cloud/spring-cloud-openfeign/issues/3"&gt;Encoding path variables with &lt;code&gt;/&lt;/code&gt; added&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;&lt;a href="#spring-cloud-contract" class="anchor" name="spring-cloud-contract"&gt;&lt;/a&gt;Spring Cloud Contract&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Several dependencies upgraded&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;&lt;a href="#spring-cloud-sleuth" class="anchor" name="spring-cloud-sleuth"&gt;&lt;/a&gt;Spring Cloud Sleuth&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href="https://github.com/spring-cloud/spring-cloud-sleuth/issues/1742"&gt;Improved the efficiency of messaging TracingChannelInterceptor&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://github.com/spring-cloud/spring-cloud-sleuth/issues/1772"&gt;Displaying method names added&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;&lt;a href="#spring-cloud-config" class="anchor" name="spring-cloud-config"&gt;&lt;/a&gt;Spring Cloud Config&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Added &lt;a href="https://github.com/spring-cloud/spring-cloud-config/pull/1593"&gt;Index regeneration&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Added &lt;a href="https://github.com/spring-cloud/spring-cloud-config/issues/717"&gt;the option to clone git submodules at start&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Improved &lt;a href="https://github.com/spring-cloud/spring-cloud-config/pull/1743"&gt;root exception handling&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;&lt;a href="#spring-cloud-consul" class="anchor" name="spring-cloud-consul"&gt;&lt;/a&gt;Spring Cloud Consul&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href="https://github.com/spring-cloud/spring-cloud-consul/issues/680"&gt;Added LoadBalancer support for &lt;code&gt;serverListQueryTags&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Several dependencies upgraded&lt;/li&gt;
&lt;/ul&gt;
&lt;hr/&gt;
&lt;p&gt;The following modules were updated as part of Hoxton.SR10:&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Module &lt;/th&gt;
      &lt;th&gt;Version &lt;/th&gt;
      &lt;th&gt;Issues&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Starter Build &lt;/td&gt;
      &lt;td&gt;Hoxton.SR10 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Netflix &lt;/td&gt;
      &lt;td&gt;2.2.7.RELEASE &lt;/td&gt;
      &lt;td&gt;(&lt;a href="https://github.com/spring-cloud/spring-cloud-netflix/milestone/96?closed=1"&gt;issues&lt;/a&gt;)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Openfeign &lt;/td&gt;
      &lt;td&gt;2.2.7.RELEASE &lt;/td&gt;
      &lt;td&gt;(&lt;a href="https://github.com/spring-cloud/spring-cloud-openfeign/milestone/31?closed=1"&gt;issues&lt;/a&gt;)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Config &lt;/td&gt;
      &lt;td&gt;2.2.7.RELEASE &lt;/td&gt;
      &lt;td&gt;(&lt;a href="https://github.com/spring-cloud/spring-cloud-config/milestone/86?closed=1"&gt;issues&lt;/a&gt;)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Aws &lt;/td&gt;
      &lt;td&gt;2.2.6.RELEASE &lt;/td&gt;
      &lt;td&gt;(&lt;a href="https://github.com/spring-cloud/spring-cloud-aws/milestone/36?closed=1"&gt;issues&lt;/a&gt;)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Gateway &lt;/td&gt;
      &lt;td&gt;2.2.7.RELEASE &lt;/td&gt;
      &lt;td&gt;(&lt;a href="https://github.com/spring-cloud/spring-cloud-gateway/milestone/44?closed=1"&gt;issues&lt;/a&gt;)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Gcp &lt;/td&gt;
      &lt;td&gt;1.2.7.RELEASE &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Commons &lt;/td&gt;
      &lt;td&gt;2.2.7.RELEASE &lt;/td&gt;
      &lt;td&gt;(&lt;a href="https://github.com/spring-cloud/spring-cloud-commons/milestone/82?closed=1"&gt;issues&lt;/a&gt;)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Consul &lt;/td&gt;
      &lt;td&gt;2.2.6.RELEASE &lt;/td&gt;
      &lt;td&gt;(&lt;a href="https://github.com/spring-cloud/spring-cloud-consul/milestone/52?closed=1"&gt;issues&lt;/a&gt;)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Contract &lt;/td&gt;
      &lt;td&gt;2.2.6.RELEASE &lt;/td&gt;
      &lt;td&gt;(&lt;a href="https://github.com/spring-cloud/spring-cloud-contract/milestone/71?closed=1"&gt;issues&lt;/a&gt;)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Kubernetes &lt;/td&gt;
      &lt;td&gt;1.1.8.RELEASE &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Sleuth &lt;/td&gt;
      &lt;td&gt;2.2.7.RELEASE &lt;/td&gt;
      &lt;td&gt;(&lt;a href="https://github.com/spring-cloud/spring-cloud-sleuth/milestone/83?closed=1"&gt;issues&lt;/a&gt;)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Vault &lt;/td&gt;
      &lt;td&gt;2.2.7.RELEASE &lt;/td&gt;
      &lt;td&gt;(&lt;a href="https://github.com/spring-cloud/spring-cloud-vault/milestone/44?closed=1"&gt;issues&lt;/a&gt;)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud CLI &lt;/td&gt;
      &lt;td&gt;2.2.4.RELEASE &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;As always, we welcome feedback on &lt;a href="https://github.com/spring-cloud/"&gt;GitHub&lt;/a&gt;, on &lt;a href="https://gitter.im/spring-cloud/spring-cloud"&gt;Gitter&lt;/a&gt;, on &lt;a href="https://stackoverflow.com/questions/tagged/spring-cloud"&gt;Stack Overflow&lt;/a&gt;, or on &lt;a href="https://twitter.com/SpringCloud"&gt;Twitter&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To get started with Maven with a BOM (dependency management only):&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint xml"&gt;&amp;lt;dependencyManagement&amp;gt;&#xD;
    &amp;lt;dependencies&amp;gt;&#xD;
        &amp;lt;dependency&amp;gt;&#xD;
            &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;&#xD;
            &amp;lt;artifactId&amp;gt;spring-cloud-dependencies&amp;lt;/artifactId&amp;gt;&#xD;
            &amp;lt;version&amp;gt;Hoxton.SR10&amp;lt;/version&amp;gt;&#xD;
            &amp;lt;type&amp;gt;pom&amp;lt;/type&amp;gt;&#xD;
            &amp;lt;scope&amp;gt;import&amp;lt;/scope&amp;gt;&#xD;
        &amp;lt;/dependency&amp;gt;&#xD;
    &amp;lt;/dependencies&amp;gt;&#xD;
&amp;lt;/dependencyManagement&amp;gt;&#xD;
&amp;lt;dependencies&amp;gt;&#xD;
    &amp;lt;dependency&amp;gt;&#xD;
        &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;&#xD;
        &amp;lt;artifactId&amp;gt;spring-cloud-starter-config&amp;lt;/artifactId&amp;gt;&#xD;
    &amp;lt;/dependency&amp;gt;&#xD;
    &amp;lt;dependency&amp;gt;&#xD;
        &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;&#xD;
        &amp;lt;artifactId&amp;gt;spring-cloud-starter-netflix-eureka-client&amp;lt;/artifactId&amp;gt;&#xD;
    &amp;lt;/dependency&amp;gt;&#xD;
    ...&#xD;
&amp;lt;/dependencies&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;or with Gradle:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint groovy"&gt;buildscript {&#xD;
  dependencies {&#xD;
    classpath &amp;quot;io.spring.gradle:dependency-management-plugin:1.0.10.RELEASE&amp;quot;&#xD;
  }&#xD;
}&#xD;
&#xD;
apply plugin: &amp;quot;io.spring.dependency-management&amp;quot;&#xD;
&#xD;
dependencyManagement {&#xD;
  imports {&#xD;
    mavenBom &amp;#39;org.springframework.cloud:spring-cloud-dependencies:Hoxton.SR10&amp;#39;&#xD;
  }&#xD;
}&#xD;
&#xD;
dependencies {&#xD;
  compile &amp;#39;org.springframework.cloud:spring-cloud-starter-config&amp;#39;&#xD;
  compile &amp;#39;org.springframework.cloud:spring-cloud-starter-netflix-eureka-client&amp;#39;&#xD;
  //...&#xD;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>Metrics and Tracing: Better Together</title>
    <link rel="alternate" href="https://spring.io/blog/2021/02/09/metrics-and-tracing-better-together" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>Tommy Ludwig</name>
    </author>
    <id>tag:spring.io,2021-02-10:4357</id>
    <updated>2021-02-10T03:22:00Z</updated>
    <content type="html">&lt;blockquote&gt;
  &lt;p&gt;This blog post was co-authored by our very own, always excited about all things Spring, &lt;a href="https://spring.io/team/joshlong"&gt;Josh Long&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;You&amp;rsquo;ve decided to put your talents to work in the service of humanity and - in the age of the pandemic, and having no other real skills to speak of besides software - you&amp;rsquo;re going to build a web service that people can check for the availability of the highly vaunted Playstation 5 video game console, on your new website, &lt;code&gt;www.ps5ownersarebetterpeople.com.net&lt;/code&gt;.&lt;/p&gt;&lt;h2&gt;&lt;a href="#it-all-started-so-auspiciously-hellip" class="anchor" name="it-all-started-so-auspiciously-hellip"&gt;&lt;/a&gt;It All Started so Auspiciously&amp;hellip;&lt;/h2&gt;
&lt;p&gt;Go to the trusty &lt;a href="https://start.spring.io"&gt;Spring Initializr&lt;/a&gt; and generate a new project (called &lt;code&gt;service&lt;/code&gt;) using the latest version of Java ( &lt;em&gt;natch!&lt;/em&gt; ) and add the &lt;code&gt;Reactive Web&lt;/code&gt;, &lt;code&gt;Wavefront&lt;/code&gt;, &lt;code&gt;Lombok&lt;/code&gt;, &lt;code&gt;Sleuth&lt;/code&gt;, and &lt;code&gt;Actuator&lt;/code&gt; dependencies to the project. Click the &lt;code&gt;Generate&lt;/code&gt; button to download a &lt;code&gt;.zip&lt;/code&gt; file containing the code for a project you should open in your favorite IDE. &lt;/p&gt;
&lt;p&gt;Add the following configuration values to &lt;a href="https://github.com/shakuzen/console-availability/tree/master/basics/service/src/main/resources/application.properties"&gt;&lt;code&gt;application.properties&lt;/code&gt;&lt;/a&gt;. We&amp;rsquo;ll review them as they become relevant. For now, the critical thing to keep in mind is that we&amp;rsquo;re running the &lt;code&gt;service&lt;/code&gt; on port &lt;code&gt;8083&lt;/code&gt;, and we&amp;rsquo;ve given this service a name with the &lt;code&gt;spring.application.name&lt;/code&gt; property, &lt;code&gt;service&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint properties"&gt;spring.application.name=service&#xD;
server.port=8083&#xD;
wavefront.application.name=console-availability&#xD;
management.metrics.export.wavefront.source=my-cloud-server
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here&amp;rsquo;s &lt;a href="https://github.com/shakuzen/console-availability/blob/master/basics/service/src/main/java/server/ServiceApplication.java"&gt;the Java code&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint java"&gt;@Slf4j&#xD;
@SpringBootApplication&#xD;
public class ServiceApplication {&#xD;
&#xD;
    public static void main(String[] args) {&#xD;
        log.info(&amp;quot;starting server&amp;quot;);&#xD;
        SpringApplication.run(ServiceApplication.class, args);&#xD;
    }&#xD;
}&#xD;
&#xD;
@RestController&#xD;
class AvailabilityController {&#xD;
&#xD;
    private boolean validate(String console) {&#xD;
        return StringUtils.hasText(console) &amp;amp;&amp;amp;&#xD;
               Set.of(&amp;quot;ps5&amp;quot;, &amp;quot;ps4&amp;quot;, &amp;quot;switch&amp;quot;, &amp;quot;xbox&amp;quot;).contains(console);&#xD;
    }&#xD;
&#xD;
    @GetMapping(&amp;quot;/availability/{console}&amp;quot;)&#xD;
    Map&amp;lt;String, Object&amp;gt; getAvailability(@PathVariable String console) {&#xD;
        return Map.of(&amp;quot;console&amp;quot;, console,&#xD;
                &amp;quot;available&amp;quot;, checkAvailability(console));&#xD;
    }&#xD;
&#xD;
    private boolean checkAvailability(String console) {&#xD;
        Assert.state(validate(console), () -&amp;gt; &amp;quot;the console specified, &amp;quot; + console + &amp;quot;, is not valid.&amp;quot;);&#xD;
        return switch (console) {&#xD;
            case &amp;quot;ps5&amp;quot; -&amp;gt; throw new RuntimeException(&amp;quot;Service exception&amp;quot;);&#xD;
            case &amp;quot;xbox&amp;quot; -&amp;gt; true;&#xD;
            default -&amp;gt; false;&#xD;
        };&#xD;
    }&#xD;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Given a request for a particular type of console (&lt;code&gt;ps5&lt;/code&gt;, &lt;code&gt;nintendo&lt;/code&gt;, &lt;code&gt;xbox&lt;/code&gt;, &lt;code&gt;ps4&lt;/code&gt;), the API returns the console&amp;rsquo;s availability (presumably sourced from local electronics outlets). Except for some reason, which for our demo will have to be &lt;em&gt;deus ex machina&lt;/em&gt; - there is no PlayStation 5 availability. Worse, the service itself is experiencing errors and blowing chunks every time someone even dares to inquire about the Playstation 5! We&amp;rsquo;ll use this particular code path - asking about the availability of Playstation 5&amp;rsquo;s in particular - to simulate an error in our system. Don&amp;rsquo;t judge. You&amp;rsquo;ve probably made an error at some point, too. Probably. &lt;/p&gt;
&lt;p&gt;We want as much information as possible about individual microservices and their interactions, and we will most want that information when we&amp;rsquo;re trying to flush out bugs in the system. Let&amp;rsquo;s see how tracing and metrics can work together to provide an observability posture superior to using either metrics or tracing alone. &lt;/p&gt;
&lt;p&gt;We&amp;rsquo;ll need a client to talk to the service and drive some traffic to it. Return to the &lt;a href="https://start.spring.io"&gt;Spring Initializr&lt;/a&gt; and generate another project precisely like the &lt;code&gt;service&lt;/code&gt;, but give this one the &lt;code&gt;spring.application.name&lt;/code&gt; value of &lt;code&gt;client&lt;/code&gt;. &lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s &lt;a href="https://github.com/shakuzen/console-availability/blob/master/basics/client/src/main/resources/application.properties"&gt;the configuration file&lt;/a&gt;. &lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint properties"&gt;spring.application.name=client&#xD;
wavefront.application.name=console-availability&#xD;
management.metrics.export.wavefront.source=my-cloud-server
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The code uses the reactive, non-blocking &lt;code&gt;WebClient&lt;/code&gt; to issue requests against the service. The entire application - both &lt;code&gt;client&lt;/code&gt; and &lt;code&gt;service&lt;/code&gt; - use reactive, non-blocking HTTP. You could just as easily use the traditional Servlet-based Spring MVC. Or you could avoid HTTP altogether and use messaging technologies. Or you could use both. Here&amp;rsquo;s &lt;a href="https://github.com/shakuzen/console-availability/blob/master/basics/client/src/main/java/client/ClientApplication.java"&gt;the Java code&lt;/a&gt;. &lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint java"&gt;@Slf4j&#xD;
@SpringBootApplication&#xD;
public class ClientApplication {&#xD;
&#xD;
    public static void main(String[] args) {&#xD;
        log.info(&amp;quot;starting client&amp;quot;);&#xD;
        SpringApplication.run(ClientApplication.class, args);&#xD;
    }&#xD;
&#xD;
    @Bean&#xD;
    WebClient webClient(WebClient.Builder builder) {&#xD;
        return builder.build();&#xD;
    }&#xD;
&#xD;
    @Bean&#xD;
    ApplicationListener&amp;lt;ApplicationReadyEvent&amp;gt; ready(AvailabilityClient client) {&#xD;
        return applicationReadyEvent -&amp;gt; {&#xD;
            for (var console : &amp;quot;ps5,xbox,ps4,switch&amp;quot;.split(&amp;quot;,&amp;quot;)) {&#xD;
                Flux.range(0, 20).delayElements(Duration.ofMillis(100)).subscribe(i -&amp;gt;&#xD;
                        client&#xD;
                                .checkAvailability(console)&#xD;
                                .subscribe(availability -&amp;gt;&#xD;
                                        log.info(&amp;quot;console: {}, availability: {} &amp;quot;, console, availability.isAvailable())));&#xD;
            }&#xD;
        };&#xD;
    }&#xD;
}&#xD;
&#xD;
@Data&#xD;
@AllArgsConstructor&#xD;
@NoArgsConstructor&#xD;
class Availability {&#xD;
    private boolean available;&#xD;
    private String console;&#xD;
}&#xD;
&#xD;
@Component&#xD;
@RequiredArgsConstructor&#xD;
class AvailabilityClient {&#xD;
&#xD;
    private final WebClient webClient;&#xD;
    private static final String URI = &amp;quot;http://localhost:8083/availability/{console}&amp;quot;;&#xD;
&#xD;
    Mono&amp;lt;Availability&amp;gt; checkAvailability(String console) {&#xD;
        return this.webClient&#xD;
                .get()&#xD;
                .uri(URI, console)&#xD;
                .retrieve()&#xD;
                .bodyToMono(Availability.class)&#xD;
                .onErrorReturn(new Availability(false, console));&#xD;
    }&#xD;
&#xD;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Start the &lt;code&gt;service&lt;/code&gt; application, and then start the &lt;code&gt;client&lt;/code&gt; application. The &lt;code&gt;client&lt;/code&gt; application generates a lot of demand directed at the service, some of which results in failed requests. We want to capture all of that information. &lt;/p&gt;&lt;h2&gt;&lt;a href="#a-number-by-any-other-name" class="anchor" name="a-number-by-any-other-name"&gt;&lt;/a&gt;A Number By Any Other Name&lt;/h2&gt;
&lt;p&gt;First, we want to have an aggregate view of all the data, &lt;em&gt;metrics&lt;/em&gt;, that give us statistics about all the requests. Metrics are numbers, aggregations. Metrics can cover things like memory/thread usage, garbage collection, process metrics, etc. They also often encompass key performance indicators that the business might set, like how many orders were fulfilled, how many users authenticated, etc.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;Actuator&lt;/code&gt; starter, in turn, brings in &lt;a href="https://micrometer.io"&gt;Micrometer&lt;/a&gt;, which provides a simple facade over the instrumentation clients for the most popular monitoring systems, allowing you to instrument your JVM-based application code without vendor lock-in. Think SLF4J, but for metrics. &lt;/p&gt;
&lt;p&gt;The most straightforward possible use of Micrometer is to capture metrics and keep them in memory, which the Spring Boot Actuator will do. You can configure your application to show those metrics under an Actuator management endpoint - &lt;code&gt;/actuator/metrics/&lt;/code&gt;. More commonly, though, you&amp;rsquo;ll want to send these metrics to a time-series database like Graphite, Prometheus, Netflix Atlas, Datadog, or InfluxDB. Time series databases store the evolving value of a metric over time, so you can see how it has changed.&lt;/p&gt;&lt;h2&gt;&lt;a href="#follow-the-data" class="anchor" name="follow-the-data"&gt;&lt;/a&gt;Follow the Data&lt;/h2&gt;
&lt;p&gt;Danger is the snack food of a true sleuth. -Mac Barnett&lt;/p&gt;
&lt;p&gt;We also want to have detailed breakdowns of individual requests and traces to give us context around particular failed requests. The &lt;code&gt;Sleuth&lt;/code&gt; starter brings in the &lt;a href="https://spring.io/projects/spring-cloud-sleuth"&gt;Spring Cloud Sleuth&lt;/a&gt; distributed tracing abstraction, which provides a simple facade over distributed tracing systems like OpenZipkin and Google Cloud Stackdriver Trace and Wavefront. &lt;/p&gt;
&lt;p&gt;Micrometer and Sleuth give you the power of choice in metrics and tracing backends. We &lt;em&gt;could&lt;/em&gt; use these two different abstractions and separately stand up a dedicated cluster for our tracing and metrics aggregation systems. People do. Crazier things have happened. We&amp;rsquo;re all about the idea that you shouldn&amp;rsquo;t run what you can&amp;rsquo;t charge for, so let&amp;rsquo;s use an easy, turnkey, hosted, software-as-a-service (SaaS) offering and let someone else do that work. We don&amp;rsquo;t envy the integration task that having such highly related data living in two different, unrelated backend systems otherwise implies. &lt;/p&gt;&lt;h2&gt;&lt;a href="#to-the-observability-cave-statsman" class="anchor" name="to-the-observability-cave-statsman"&gt;&lt;/a&gt;To The Observability Cave, Statsman!&lt;/h2&gt;
&lt;p&gt;We will use VMware Tanzu&amp;rsquo;s &lt;a href="https://tanzu.vmware.com/observability"&gt;excellent Wavefront observability platform&lt;/a&gt;, which understands both metrics and traces and can link them together for us. We already added the &lt;code&gt;Wavefront&lt;/code&gt; starter to our build.&lt;/p&gt;
&lt;p&gt;Start the &lt;code&gt;service&lt;/code&gt; and then start the &lt;code&gt;client&lt;/code&gt;. The &lt;code&gt;client&lt;/code&gt; will generate a lot of traffic. Well, not a &lt;em&gt;lot&lt;/em&gt;. Remember, &lt;a href="https://en.wikipedia.org/wiki/Reddit"&gt;Reddit&lt;/a&gt; uses Wavefront successfully at their global scale. So, all things being equal, our data is &lt;em&gt;nothing&lt;/em&gt;. But it&amp;rsquo;s enough to see some core concepts in action. A Wavefront URL is printed out when our Spring Boot application starts up. This is the URL to access the &lt;em&gt;freemium&lt;/em&gt; Wavefront cluster. You already have a valid Wavefront configuration, and you didn&amp;rsquo;t even have to sign up for an account! It will take a minute for metrics to publish to Wavefront. Wait for a minute and then visit the URL printed in the console in your browser.&lt;/p&gt;
&lt;p&gt;That URL dumps you into the Wavefront dashboard for Spring Boot. There&amp;rsquo;s a lot here, so we&amp;rsquo;ll focus on a few key things in particular. &lt;/p&gt;
&lt;img src = "https://github.com/shakuzen/console-availability/raw/master/images/1.png" width = "500" /&gt;
&lt;p&gt;You can see that Wavefront comes fully loaded with a &lt;code&gt;Spring Boot&lt;/code&gt; dashboard in the &lt;code&gt;Dashboards&lt;/code&gt; menu at the top of the screen. The top of the dashboard shows that the &lt;code&gt;Source&lt;/code&gt; is &lt;code&gt;my-cloud-server&lt;/code&gt;, which comes from the configuration property &lt;code&gt;management.&#xD;
.export.wavefront.source&lt;/code&gt; (or use the default, which is the hostname of the machine). The &lt;code&gt;Application&lt;/code&gt; we&amp;rsquo;re interested in is &lt;code&gt;console-availability&lt;/code&gt;, which comes from the configuration property &lt;code&gt;wavefront.application.name&lt;/code&gt;. &lt;em&gt;Application&lt;/em&gt; refers to the logical group of Spring Boot microservices, not any specific one. &lt;/p&gt;
&lt;img src = "https://github.com/shakuzen/console-availability/raw/master/images/2.png" width = "500" /&gt;
&lt;p&gt;Click on that, and you&amp;rsquo;ll see everything about your application at a glance. You can choose to look at information for either module - &lt;code&gt;client&lt;/code&gt; or &lt;code&gt;service&lt;/code&gt;. Click &lt;code&gt;Jump To&lt;/code&gt; to navigate to a particular set of graphs. We&amp;rsquo;re interested in the data in the &lt;code&gt;HTTP&lt;/code&gt; section. &lt;/p&gt;
&lt;img src = "https://github.com/shakuzen/console-availability/raw/master/images/4.png" width = "500" /&gt;
&lt;p&gt;You can see a useful thing like the &lt;code&gt;Top Requests&lt;/code&gt;, the &lt;code&gt;Top Failed Requests&lt;/code&gt;, and &lt;code&gt;Top Exceptions&lt;/code&gt; encountered in the code - mouse over a particular type of request to get some details associated with each entry. You can get information like the HTTP method (&lt;code&gt;GET&lt;/code&gt;), service (&lt;code&gt;service&lt;/code&gt;), status code (&lt;code&gt;500&lt;/code&gt;), and URI (&lt;code&gt;/availability/{console}&lt;/code&gt;) associated with the failing requests.&lt;/p&gt;
&lt;p&gt;These kinds of at-a-glance numbers are metrics. Metrics are not based on sampled data; they&amp;rsquo;re an aggregation of every single request. You should use metrics for your alerting because they ensure that you see &lt;em&gt;all&lt;/em&gt; your requests (and &lt;em&gt;all&lt;/em&gt; the errors, slow requests, etc.). Trace data, on the other hand, usually needs to be sampled at high volumes of traffic because the amount of data increases proportionally to the traffic volume.&lt;/p&gt;
&lt;p&gt;We can see that the metrics collection has ignored the values for the &lt;code&gt;{console}&lt;/code&gt; path variable in distinguishing the requests, which means that - as far as our data is concerned - there&amp;rsquo;s only one URI (&lt;code&gt;/availability/{console}&lt;/code&gt;). This is by design. &lt;code&gt;{console}&lt;/code&gt; is a path variable we&amp;rsquo;re using to specify the console, but it could just as easily have been a user ID, an order ID, or some other thing for which there are likely many, possibly unbounded, values. It would be dangerous for the metrics system to record high cardinality metrics by default. Bounded cardinality metrics are cheap! Cost does not increase with traffic. Watch for cardinality in your metrics.&lt;/p&gt;
&lt;p&gt;It is a little unfortunate because even though we know that &lt;code&gt;{console}&lt;/code&gt; is a low-cardinality variable - there&amp;rsquo;s a finite set of possible values - we can&amp;rsquo;t drill down into the data any further to see at a glance which paths are failing. Metrics represent aggregated statistics, so even if we broke down the metrics in terms of the &lt;code&gt;{console}&lt;/code&gt; variable, the metrics still lacks context around individual requests.&lt;/p&gt;
&lt;p&gt;There&amp;rsquo;s always the trace data! Click on the little breadcrumb/sandwich icon to the right of the words &lt;code&gt;Top Failed Requests&lt;/code&gt;, and find the service by going to &lt;code&gt;Traces&lt;/code&gt; &amp;gt; &lt;code&gt;console-availability&lt;/code&gt;. &lt;/p&gt;
&lt;img src = "https://github.com/shakuzen/console-availability/raw/master/images/5.png" width = "500" /&gt;
&lt;p&gt;Here are all the traces collected for the application: good, bad, or otherwise. &lt;/p&gt;
&lt;img src = "https://github.com/shakuzen/console-availability/raw/master/images/6.png" width = "500" /&gt;
&lt;p&gt;Let&amp;rsquo;s drill down into only the errant requests by adding an &lt;code&gt;Error&lt;/code&gt; filter to the search. Then click &lt;code&gt;Search&lt;/code&gt;. Now we can scrutinize individual errant requests. You can see how long was taken in each service call, the relationship between services, and where the error originated.&lt;/p&gt;
&lt;img src = "https://github.com/shakuzen/console-availability/raw/master/images/8.png" width = "500" /&gt;
&lt;p&gt;Click on the &lt;code&gt;Expand&lt;/code&gt; icon for the panel labeled &lt;code&gt;client: GET&lt;/code&gt; in the screen&amp;rsquo;s bottom right. You can see each hop in the request&amp;rsquo;s journey: how long it took, the trace ID, the URL, and the path.&lt;/p&gt;
&lt;img src = "https://github.com/shakuzen/console-availability/raw/master/images/9.png" width = "500" /&gt;
&lt;p&gt;Expand the &lt;code&gt;Tags&lt;/code&gt; branch under a particular segment of the trace, and you can see the metadata collected on your behalf, automatically, by Spring Cloud Sleuth. A trace is made up of individual segments, called &lt;em&gt;spans&lt;/em&gt;, that describe one hop in the request&amp;rsquo;s journey.&lt;/p&gt;
&lt;img src = "https://github.com/shakuzen/console-availability/raw/master/images/10.png" width = "500" /&gt;&lt;h2&gt;&lt;a href="#enriching-the-data-with-business-domain-context" class="anchor" name="enriching-the-data-with-business-domain-context"&gt;&lt;/a&gt;Enriching the Data with Business/Domain Context&lt;/h2&gt;
&lt;p&gt;We got a lot out of the default configuration. We didn&amp;rsquo;t really do anything to the code to get the results we just saw except for adding the Spring Boot &lt;code&gt;Actuator&lt;/code&gt; starter, the &lt;code&gt;Wavefront&lt;/code&gt; starter, and the &lt;code&gt;Sleuth&lt;/code&gt; starter and starting the application. See? It was easy! Very easy. As easy as falling off a log&amp;hellip;ging-centric system and onto a real observability platform, even. We got trace information and metrics and a dashboard that we could consult for the details. We made precisely zero changes to our Java code to support any of this.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s take things a bit further and customize the metadata captured by Spring Cloud Sleuth and Micrometer to make it even easier to drill down by a domain-specific concept: the type of console requested. We can do this with the &lt;code&gt;{console}&lt;/code&gt; path variable. The code already validates that the console&amp;rsquo;s value falls within a set of well-known consoles. It is important that we validate the input before using it, which ensures the type of console is low cardinality. You should not use arbitrary input (like a path variable or query parameter) that could be high cardinality as a metric tag - though you could use high cardinality data as a trace tag. Now, instead of gleaning the type of console from the HTTP path in the trace data, we can use a tag on the metrics and traces.&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;ll update the service to inject a &lt;code&gt;SpanCustomizer&lt;/code&gt; to customize the trace information. We&amp;rsquo;ll also update the service to configure a &lt;code&gt;WebFluxTagsContributor&lt;/code&gt; to customize the tags captured by Spring Boot and given to Micrometer. Here&amp;rsquo;s the &lt;a href="https://github.com/shakuzen/console-availability/blob/master/enhanced/service/src/main/java/server/ServiceApplication.java"&gt;new and updated code&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint java"&gt;@Slf4j&#xD;
@SpringBootApplication&#xD;
public class ServiceApplication {&#xD;
&#xD;
    @Bean&#xD;
    WebFluxTagsContributor consoleTagContributor() {&#xD;
        return (exchange, ex) -&amp;gt; {&#xD;
            var console = &amp;quot;UNKNOWN&amp;quot;;&#xD;
            var consolePathVariable = ((Map&amp;lt;String,String&amp;gt;) exchange.getAttribute(HandlerMapping.URI_TEMPLATE_VARIABLES_ATTRIBUTE)).get(&amp;quot;console&amp;quot;);&#xD;
            if (AvailabilityController.validateConsole(consolePathVariable)) {&#xD;
                console = consolePathVariable;&#xD;
            }&#xD;
            return Tags.of(&amp;quot;console&amp;quot;, console);&#xD;
        };&#xD;
    }&#xD;
&#xD;
    public static void main(String[] args) {&#xD;
        log.info(&amp;quot;starting server&amp;quot;);&#xD;
        SpringApplication.run(ServiceApplication.class, args);&#xD;
    }&#xD;
}&#xD;
&#xD;
@RestController&#xD;
@AllArgsConstructor&#xD;
class AvailabilityController {&#xD;
&#xD;
    private final SpanCustomizer spanCustomizer;&#xD;
&#xD;
    @GetMapping(&amp;quot;/availability/{console}&amp;quot;)&#xD;
    Map&amp;lt;String, Object&amp;gt; getAvailability(@PathVariable String console) {&#xD;
        Assert.state(validateConsole(console), () -&amp;gt; &amp;quot;the console specified, &amp;quot; + console + &amp;quot;, is not valid.&amp;quot;);&#xD;
        this.spanCustomizer.tag(&amp;quot;console&amp;quot;, console);&#xD;
        return Map.of(&amp;quot;console&amp;quot;, console, &amp;quot;available&amp;quot;, checkAvailability(console));&#xD;
    }&#xD;
&#xD;
    private boolean checkAvailability(String console) {&#xD;
        return switch (console) {&#xD;
            case &amp;quot;ps5&amp;quot; -&amp;gt; throw new RuntimeException(&amp;quot;Service exception&amp;quot;);&#xD;
            case &amp;quot;xbox&amp;quot; -&amp;gt; true;&#xD;
            default -&amp;gt; false;&#xD;
        };&#xD;
    }&#xD;
&#xD;
    static boolean validateConsole(String console) {&#xD;
        return StringUtils.hasText(console) &amp;amp;&amp;amp;&#xD;
               Set.of(&amp;quot;ps5&amp;quot;, &amp;quot;ps4&amp;quot;, &amp;quot;switch&amp;quot;, &amp;quot;xbox&amp;quot;).contains(console);&#xD;
    }&#xD;
&#xD;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Re-run the service with the above changes and then the client (same as before), and wait a minute for metrics to be published. Then open up the Wavefront console again; use that handy link printed in the console output!&lt;/p&gt;
&lt;p&gt;You can now see different metrics broken down by the console. Click on &lt;code&gt;Dashboards&lt;/code&gt; &amp;gt; &lt;code&gt;Spring Boot Dashboard&lt;/code&gt;, and you&amp;rsquo;ll note that the &lt;code&gt;Top Requests&lt;/code&gt; and &lt;code&gt;Top Failed Requests&lt;/code&gt; have more entries. This time, you may break down the results in terms of each console. Hover over them, and you&amp;rsquo;ll see the details. &lt;/p&gt;
&lt;p&gt;Here are successful requests.&lt;/p&gt;
&lt;img src = "https://github.com/shakuzen/console-availability/raw/master/images/15.png" width = "500" /&gt;
&lt;p&gt;Here are failed requests.&lt;/p&gt;
&lt;img src = "https://github.com/shakuzen/console-availability/raw/master/images/16.png" width = "500" /&gt;
&lt;p&gt;It seems to us that the &lt;code&gt;ps5&lt;/code&gt; console has a high coincidence with the failed requests. Let&amp;rsquo;s look at the trace information. Click on &lt;code&gt;Applications&lt;/code&gt; &amp;gt; &lt;code&gt;Traces&lt;/code&gt;, to see the updated data. &lt;/p&gt;
&lt;img src = "https://github.com/shakuzen/console-availability/raw/master/images/11.png" width = "500" /&gt;
&lt;p&gt;Click on the critical path breakdown and expand the panel. Click on a particular segment, as shown here, and extend the &lt;code&gt;Tags&lt;/code&gt; branch. You&amp;rsquo;ll see all the tags associated with a particular request, including the &lt;code&gt;console&lt;/code&gt; tag. The failing request depicted was after someone requested the availability of the &lt;code&gt;ps5&lt;/code&gt; console. It&amp;rsquo;d sure be nice to filter based on the console, wouldn&amp;rsquo;t it? Click the &lt;code&gt;+&lt;/code&gt; icon next to the tag &lt;code&gt;console&lt;/code&gt;, and Wavefront will add it to the search criteria. Click &lt;code&gt;Search&lt;/code&gt; to see all the errant traces and find the culprits.&lt;/p&gt;
&lt;img src = "https://github.com/shakuzen/console-availability/raw/master/images/12.png" width = "500" /&gt;
&lt;p&gt;Our data breaks down both traces and metrics in terms of the console, our domain-specific concept.&lt;/p&gt;&lt;h2&gt;&lt;a href="#metrics-and-tracing-go-together-like-chicken-and-pickle-brine" class="anchor" name="metrics-and-tracing-go-together-like-chicken-and-pickle-brine"&gt;&lt;/a&gt;Metrics and Tracing Go Together like Chicken and Pickle Brine&lt;/h2&gt;
&lt;p&gt;What? You&amp;rsquo;ve &lt;em&gt;never&lt;/em&gt; tried chicken and pickle brine? It&amp;rsquo;s good. It&amp;rsquo;s &lt;a href="https://www.eatthis.com/weird-food-combinations/"&gt;really good&lt;/a&gt;. Can you imagine how much more free time you&amp;rsquo;ll have once you&amp;rsquo;ve standardized on Spring and Wavefront and don&amp;rsquo;t have to maintain as much undifferentiated infrastructure yourself? It&amp;rsquo;s gonna be sweet. You&amp;rsquo;ll have so much time. You&amp;rsquo;ll have time enough to try chicken and pickle brine. &lt;/p&gt;
&lt;p&gt;You have seen a concrete example of using metrics and tracing together. Let&amp;rsquo;s review some uses and anti-patterns for metrics and tracing. This hopefully makes clear why you want both metrics and tracing and how to use each for what. It may be useful to consider the framing set up in &lt;a href="https://peter.bourgon.org/blog/2017/02/21/metrics-tracing-and-logging.html"&gt;Peter Bourgon&amp;rsquo;s Metrics, tracing, and logging&lt;/a&gt; blog post.&lt;/p&gt;
&lt;p&gt;Tracing and metrics overlap in providing insight on request-scoped interactions in our services. However, some information provided by metrics and tracing is disjointed. Traces excel at showing the relationship between services as well as high-cardinality data about a specific request, such as a user ID associated with a request. Distributed tracing helps you pinpoint the source of an issue in your distributed system quickly. The tradeoff is that at high volumes and strict performance requirements, traces need to be sampled to control costs. This means that the specific request you are interested in may not be in the sampled tracing data. &lt;/p&gt;
&lt;p&gt;On the other side of the coin, metrics aggregate all measurements and export the aggregate at time intervals to define the time series data. All data is included in this aggregation and cost does not increase with traffic, so long as best practices on tag cardinality are followed. Therefore, a metric measuring the maximum latency of something will include the slowest request, and a calculation of error rate will be accurate, regardless of any sampling on tracing data.&lt;/p&gt;
&lt;p&gt;Metrics can be used beyond the scope of requests for monitoring memory, CPU usage, garbage collection, and caches, to name a few. You will want to use metrics for your alerting, SLOs (service-level objectives), and dashboards. In the &lt;code&gt;console-availability&lt;/code&gt; example, it would be an alert about an SLO violation that notifies us about a high error rate for our service. (You don&amp;rsquo;t want to stare at dashboards 24/7 to detect issues, do you?)&lt;/p&gt;
&lt;p&gt;Then, with both metrics and traces, we can jump from one to the other using common metadata available in each. Both metrics and trace information support capturing arbitrary key-value pairs with the data called tags. For example, given an alert notification about high latency on an HTTP-based service (based on metrics), you could link to a search of spans (trace data) that match the alert. You would search for spans with the same service, HTTP method, HTTP URI, and that are above a duration threshold to quickly get a sampling of traces matching the alert.&lt;/p&gt;
&lt;p&gt;In conclusion, data is better than no data, and integrated data is better than non-integrated data. Micrometer and Spring Cloud Sleuth provides a solid observability posture, out of the box, but can be configured and adapted to your business/domain&amp;rsquo;s context. And, finally, while you &lt;em&gt;could&lt;/em&gt; use Micrometer or Spring Cloud Sleuth with any number of other backends, we find Wavefront a convenient and powerful option. The code shown in the example is available from &lt;a href="https://github.com/shakuzen/console-availability"&gt;this GitHub repository&lt;/a&gt;.&lt;/p&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>This Week in Spring - February 9th, 2020</title>
    <link rel="alternate" href="https://spring.io/blog/2021/02/09/this-week-in-spring-february-9th-2020" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>Josh Long</name>
    </author>
    <id>tag:spring.io,2021-02-09:4356</id>
    <updated>2021-02-09T17:42:00Z</updated>
    <content type="html">&lt;p&gt;Hi, Spring fans! Welcome to another installment of &lt;em&gt;This Week in Spring&lt;/em&gt;! &lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m &lt;em&gt;just&lt;/em&gt; about to give a 2h presentation &lt;a href="https://twitter.com/VMwareTanzuNL/status/1358876516256514055"&gt;for the OOP conference&lt;/a&gt;. It&amp;rsquo;s live. It&amp;rsquo;ll be fun. Join us? &lt;/p&gt;
&lt;p&gt;How&amp;rsquo;ve you been? You realize it&amp;rsquo;s already the second week of February? Chinese New Year, a holiday celebrated by more than two billion people, begins on the 12th of February. So, seeing as how we won&amp;rsquo;t get to talk again until after, let me wish everyone who celebrates: Êñ∞Âπ¥Âø´‰πê! &lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2021/02/04/a-bootiful-podcast-rsocket-legend-and-new-reactor-team-member-oleh-dokuka"&gt;A Bootiful Podcast: RSocket legend and new Reactor team member Oleh Dokuka&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://github.com/linux-china/rsocket-load-balancing"&gt;Alibaba&amp;rsquo;s Jacky Chan has put together an awesome project that does client-side load balancing with Spring Cloud, but based on RSocket - very convenient!&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2021/02/03/demystifying-spring-cloud-stream-producers-with-apache-kafka-partitions"&gt;Demystifying Spring Cloud Stream producers with Apache Kafka partitions&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://blogs.vmware.com/opensource/2021/02/02/2021-a-look-ahead-for-open-source-at-vmware/"&gt;2021: A Look Ahead for Open Source at VMware&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://twitter.com/sivalabs/status/1357497634320117760?s=12"&gt;A New Yeoman code generator for Spring Boot (that &lt;em&gt;isn&amp;rsquo;t&lt;/em&gt; the amazing JHipster?). Looks interesting&amp;hellip;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=vruk51nnr9s&amp;feature=share"&gt;A Spring Boot REST API powered by Redis, part 2&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://github.com/domaframework/doma-spring-boot"&gt;A Spring Boot starter for the Doma mapping framework&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://medium.com/sipios/handle-r2dbc-in-spring-projects-fa96e65ca24d"&gt;A great blog, &lt;em&gt;Handle R2DBC in Spring Projects&lt;/em&gt;, by Thibault MONEGIER du SORBIER&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://tanzu.vmware.com/developer/guides/kubernetes/velero-gs/"&gt;A very useful guide to backups in Kubernetes, &lt;em&gt;Getting Started with Velero&lt;/em&gt;, by teammate and legend &lt;a href="https://twitter.com/tiffanyfayj"&gt;Tiffany Jernigan&lt;/a&gt;, is now available on the VMware Tanzu Developer Center&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://twitter.com/TheApacheTomcat/status/1356952799360282624?s=20"&gt;Apache Tomcat 10.0.2 has been released This is the first stable release of the 10.0.x series. Apache Tomcat 10.0.x targets Jakarta EE 9 (Servlet, WebSocket, EL, Pages, Authentication &amp;amp; Annotations)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.youtube.com/watch?app=desktop&amp;v=1i96a_0wCFM&amp;feature=youtu.be"&gt;Build a Secure Spring Data JPA Resource Server&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=XJoJCMfCSTk&amp;feature=emb_title"&gt;Building a Spring Boot REST API powered by Redis, with a React front end (part 1)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://medium.com/graalvm/graalvm-native-image-quick-reference-4ceb84560fd8"&gt;GraalVM Native Image Quick Reference&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://open.spotify.com/episode/3a6zZKPhiHnDIQdLAWyUOs?si=obyIclVKTOyeL8yG0hnv1Q&amp;nd=1"&gt;I was honored to have been a guest on the Devpod podcast. It was a fun interview and I hope you&amp;rsquo;ll enjoy it, too.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.meetup.com/seajug/events/276135388/"&gt;I&amp;rsquo;ll be speaking at the Seattle JUG Meetup on February 16th, 2021. Mark your calendars now and join us then!&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://twitter.com/JavaAtMicrosoft/status/1357078493746528259"&gt;Learn more about what Microsoft Azure has to offer Java developers? Attend this fast-paced, virtual intro session at the Microsoft Reactor led by Rory Preddy on Feb-10&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=bidnkrluql4&amp;feature=share"&gt;The Transparent Software Developer - some interesting insight in this video&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://twitter.com/VMware/status/1356739950620905472"&gt;We‚Äôre excited to announce dates for VMware conferences slated for this year &amp;ndash; VMworld, CloudLIVE, Connect, and SpringOne!&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>A Bootiful Podcast:  RSocket legend and new Reactor team member Oleh Dokuka</title>
    <link rel="alternate" href="https://spring.io/blog/2021/02/04/a-bootiful-podcast-rsocket-legend-and-new-reactor-team-member-oleh-dokuka" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>Josh Long</name>
    </author>
    <id>tag:spring.io,2021-02-05:4355</id>
    <updated>2021-02-05T04:24:00Z</updated>
    <content type="html">&lt;p&gt;Hi, Spring fans! Welcome to another installment of &lt;em&gt;A Bootiful Podcast&lt;/em&gt;! In this episode, &lt;a href="https://twitter.com/starbuxman"&gt;Josh Long (@starbuxman)&lt;/a&gt; talks to RSocket legend and new Reactor team member &lt;a href="https://twitter.com/OlehDokuka"&gt;Oleh Dokuka (@OlehDokuka)&lt;/a&gt; about RSocket routing, the RSocket broker, Netty, HTTP3 and Quick, the &lt;code&gt;RSocketClient&lt;/code&gt;, and so much more. &lt;/p&gt;
&lt;iframe title="RSocket legend and new Reactor team member Oleh Dokuka " height="122" width="100%" style="border: none;" scrolling="no" data-name="pb-iframe-player" src="https://www.podbean.com/media/player/m4ht5-f9c3eb?from=pb6admin&amp;download=1&amp;version=1&amp;auto=0&amp;share=1&amp;download=1&amp;rtl=0&amp;fonts=Helvetica&amp;skin=1&amp;pfauth=&amp;btn-skin=107"&gt;&lt;/iframe&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>Making the most of available resources for Spring Boot</title>
    <link rel="alternate" href="https://spring.io/blog/2021/02/04/making-the-most-of-available-resources-for-spring-boot" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>Madhura Bhave</name>
    </author>
    <id>tag:spring.io,2021-02-05:4354</id>
    <updated>2021-02-05T00:55:00Z</updated>
    <content type="html">&lt;div class="paragraph"&gt;
&lt;p&gt;Whether you&amp;#8217;re a long time user of Spring Boot or just getting started with it, there are numerous resources out there that you can leverage. Knowing what&amp;#8217;s available for your specific need is not always obvious and this blog post is aimed toward helping you to navigate through these resources.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="learning"&gt;&lt;a class="anchor" href="#learning"&gt;&lt;/a&gt;Learning&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="reference-documentation"&gt;&lt;a class="anchor" href="#reference-documentation"&gt;&lt;/a&gt;Reference Documentation&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;As a software developer, you probably already know that reading any project&amp;#8217;s documentation can help you save a lot of time and effort. The &lt;a href="https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/"&gt;Spring Boot reference documentation&lt;/a&gt; is a comprehensive document containing everything you need to know about Spring Boot. It is available in multiple formats, multi-page HTML, single-page HTML, and PDF. You can choose the one that suits your needs. The documentation is versioned, with &lt;code&gt;current&lt;/code&gt; pointing to the latest GA release. Be sure to read the documentation of the version that you are currently on. For example, if you&amp;#8217;re on Spring Boot 2.3.8, the reference documentation would be available at &lt;a href="https://docs.spring.io/spring-boot/docs/2.3.8.RELEASE/reference/htmlsingle/" class="bare"&gt;https://docs.spring.io/spring-boot/docs/2.3.8.RELEASE/reference/htmlsingle/&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Spring Boot builds on a number of other projects, each with their own reference documentation. You can find a complete list of these projects and their documentation &lt;a href="https://spring.io/projects"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="spring-guides"&gt;&lt;a class="anchor" href="#spring-guides"&gt;&lt;/a&gt;Spring Guides&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The reference documentation is information-oriented and while it contains a wealth of information, it can be a bit overwhelming for newcomers. If you&amp;#8217;re looking to get started with Spring Boot or try out specific real-world scenarios, &lt;a href="https://spring.io/guides/"&gt;Spring Guides&lt;/a&gt; provide a curated list of hands-on instructions that you can follow.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="upgrading"&gt;&lt;a class="anchor" href="#upgrading"&gt;&lt;/a&gt;Upgrading&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Without the right guidance, upgrading software can be a long and tedious process. On the Spring Boot team, we try to maintain back-compatibility as much as possible but occasionally break things when that is the best option. To minimize upgrade pain, each minor and major release is accompanied with detailed release notes containing upgrade instructions at the top.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="release-notes"&gt;&lt;a class="anchor" href="#release-notes"&gt;&lt;/a&gt;Release Notes&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The release notes are available on the &lt;a href="https://github.com/spring-projects/spring-boot/wiki"&gt;Spring Boot Wiki&lt;/a&gt;. In order to make the migration as smooth as possible, we recommend not skipping versions. If you are more than one release behind, please make sure that you also review the release notes of the versions that you jumped.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="changelog"&gt;&lt;a class="anchor" href="#changelog"&gt;&lt;/a&gt;Changelog&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;If you&amp;#8217;re just looking to get a quick glimpse at the list of changes that went into a particular release, every released version is associated with a &lt;a href="https://github.com/spring-projects/spring-boot/releases"&gt;changelog&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="planning-an-upgrade"&gt;&lt;a class="anchor" href="#planning-an-upgrade"&gt;&lt;/a&gt;Planning an upgrade&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Depending on the version you are upgrading to, you might need to plan in advance to allocate enough time for the upgrade. Here are some resources that can help with planning:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/spring-projects/spring-boot/wiki/Supported-Versions"&gt;Spring Boot Support Policy&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://github.com/spring-projects/spring-boot/milestones"&gt;Upcoming release dates&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://calendar.spring.io/"&gt;Spring release calendar&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Additionally, every minor and major release is accompanied with milestone releases. Even if you don&amp;#8217;t try out the milestones, you can look at the changelog for the milestone release to get an idea of the amount of changes that you will need to make to your project when upgrading. The release notes are also updated with every milestone release.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="getting-help-from-the-community"&gt;&lt;a class="anchor" href="#getting-help-from-the-community"&gt;&lt;/a&gt;Getting help from the community&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The Spring community is large with lots of helpful people willing to answer questions. If you have trouble with Spring Boot, you can ask questions on the &lt;a href="https://gitter.im/spring-projects/spring-boot"&gt;Spring Boot Gitter&lt;/a&gt; channel or on &lt;a href="https://stackoverflow.com"&gt;StackOverflow&lt;/a&gt; with the &lt;code&gt;spring-boot&lt;/code&gt; tag. Before asking your question, it&amp;#8217;s a good idea to verify that someone else hasn&amp;#8217;t already got an answer to the same question. A simple google search should help with that.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect1"&gt;
&lt;h2 id="reporting-issues"&gt;&lt;a class="anchor" href="#reporting-issues"&gt;&lt;/a&gt;Reporting issues&lt;/h2&gt;
&lt;div class="sectionbody"&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;We like to use the Spring Boot issue tracker for tracking bugs and enhancements. If you think you&amp;#8217;ve found a bug in Spring Boot or would like to request an enhancement, you can create a new issue on the &lt;a href="https://github.com/spring-projects/spring-boot/issues"&gt;issue tracker&lt;/a&gt;. In case you&amp;#8217;ve found a bug, attaching a minimal sample to the issue that reproduces the issue is very helpful for the maintainers. A minimal sample can be created by going to &lt;a href="https://start.spring.io"&gt;start.spring.io&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;We hope that, for most scenarios, you will find what you need in these resources. If you stumble upon a problem in them, or find that something is missing, we would love for you to help us &lt;a href="https://github.com/spring-projects/spring-boot/issues"&gt;improve them&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>Demystifying Spring Cloud Stream producers with Apache Kafka partitions</title>
    <link rel="alternate" href="https://spring.io/blog/2021/02/03/demystifying-spring-cloud-stream-producers-with-apache-kafka-partitions" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>Soby Chacko</name>
    </author>
    <id>tag:spring.io,2021-02-03:4352</id>
    <updated>2021-02-03T20:24:00Z</updated>
    <content type="html">&lt;div class="paragraph"&gt;
&lt;p&gt;In this blog, we are taking a deeper look at writing a Spring Cloud Stream producer with Apache Kafka and how it handles native partitions in Kafka.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Spring Cloud Stream has a middleware agnostic concept of partitions. Whenever possible, Spring Cloud Stream leverages the native partitioning capabilities of the middleware if it has such capabilities as in the case of Apache Kafka. This blog looks at how a Spring Cloud Stream developer handles partitions when writing a producer application that publishes data to Kafka. In a subsequent article, we will look at how consumers handle partitions in a Kafka based Spring Cloud Stream application.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Partitions are the basic unit of scaling and parallelism in Apache Kafka. Using the right partitioning strategies allows your application to handle terabytes of data at scale with minimal latency. A Kafka producer can write to different partitions in parallel, which generally means that 	it can achieve higher levels of throughput. While partitioning has these obvious upsides, there are other various considerations one needs to carefully make. Within a partition itself, throughput may be further limited by factors such as batching size, compression algorithms used, type of acknowledgments, replication factor, etc. Further, having more partitions means more open file handles (because partitions map to a directory on the broker and each log segment within a partition needs an index file and a data file). There are plenty of resources available on the web on how to come up with the right number of partitions for a Kafka application, which you may want to get familiar with before deploying your Kafka based enterprise producer application.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="spring-cloud-stream-provisioner-for-kafka-binder"&gt;&lt;a class="anchor" href="#spring-cloud-stream-provisioner-for-kafka-binder"&gt;&lt;/a&gt;Spring Cloud Stream Provisioner for Kafka binder&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Spring Cloud Stream Kafka binder has a topic provisioner that handles the various application-level topic requirements. Among other things, creating and modifying the number of partitions is something that the provisioner is capable of doing. The Provisioner itself is not doing these operations but calls the right admin APIs from the Kafka cluster.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;There are two scenarios that deal with topic creation that could come up with when writing a Spring Cloud Stream Kafka application in general. Most enterprises lock down access to the Kafka cluster and only an admin can make such operational changes as creating a topic, adding partitions, etc. In this scenario, the applications cannot directly create or modify topics. The other scenario is that the enterprise is pretty relaxed when it comes to giving access to the Kafka cluster in that the applications are free to create or modify the topics. Let‚Äôs consider a few of these things further.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="sect3"&gt;
&lt;h4 id="scenario-1-application-has-full-admin-privileges-on-the-kafka-cluster"&gt;&lt;a class="anchor" href="#scenario-1-application-has-full-admin-privileges-on-the-kafka-cluster"&gt;&lt;/a&gt;Scenario 1: Application has full admin privileges on the Kafka Cluster&lt;/h4&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In this scenario, the application has full admin access to the Kafka cluster. You are writing a Spring Cloud Stream producer that publishes messages to a Kafka topic. For the sake of our discussion, let‚Äôs assume that this topic is non-existent and your application will create it. You also want to make sure that the topic is provisioned with a certain number of partitions.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;There are a couple of ways to tell Spring Cloud Stream, how many partitions you want the topic to be provisioned with. Each one has pros and cons. Let‚Äôs look at them.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Use a binder wide property to specify the partition count. Using this, any topic that you create will have the same partition count. If your application is creating multiple topics and they all want the same number of partitions, this is an ideal way to create partitions. The disadvantage of this approach is that this is non-configurable per-binding unless overridden. The property you use at the binder level is the following.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&lt;code&gt;spring.cloud.stream.kafka.binder.min-partition-count&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Another option is to have the partition count specified at the binding level. Using this approach, you can have multiple topics in the same application configured with different partition counts. The following is the property&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&lt;code&gt;spring.cloud.stream.bindings.&amp;lt;binding-name&amp;gt;.producer.partition-count&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Given that the previous global property enforces a minimum (it could be larger), the larger of the two will take effect for a specific binding.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="ulist"&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;If neither of the above options is used, then the topic will be created with the number of partitions based on the broker &lt;code&gt;num.partitions&lt;/code&gt; property (default: 1).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect3"&gt;
&lt;h4 id="scenario-2-kafka-cluster-is-locked-down-and-the-application-is-not-allowed-to-perform-any-admin-operations"&gt;&lt;a class="anchor" href="#scenario-2-kafka-cluster-is-locked-down-and-the-application-is-not-allowed-to-perform-any-admin-operations"&gt;&lt;/a&gt;Scenario 2: Kafka Cluster is locked down and the application is not allowed to perform any admin operations.&lt;/h4&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In this scenario, your options as an application developer are very limited. Since the Kafka cluster is locked down, the application will not be able to create or change existing topics. If the topic is not created beforehand, your application will throw an exception during startup and fail. In order to avoid this, you have to make sure that the topic is created with the right number of partitions and disable automatic topic provisioning using the binder property (spring.cloud.stream.kafka.binder.auto-create-topics set to false).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect3"&gt;
&lt;h4 id="scenario-3-application-has-full-admin-privileges-on-the-kafka-cluster-and-the-topic-already-exists-but-you-want-to-increase-the-partitions-next-time-the-application-starts"&gt;&lt;a class="anchor" href="#scenario-3-application-has-full-admin-privileges-on-the-kafka-cluster-and-the-topic-already-exists-but-you-want-to-increase-the-partitions-next-time-the-application-starts"&gt;&lt;/a&gt;Scenario 3: Application has full admin privileges on the Kafka Cluster and the topic already exists, but you want to increase the partitions next time the application starts.&lt;/h4&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;This is possible. Let‚Äôs say that your topic is already provisioned with 64 partitions, now you want to double that to 128 due to some higher capacity requirements. You let the binder know that by using either of the properties discussed in scenario 1. (&lt;code&gt;spring.cloud.stream.kafka.binder.min-partition-count&lt;/code&gt; or &lt;code&gt;spring.cloud.stream.bindings.&amp;lt;binding-name&amp;gt;.producer.partition-count&lt;/code&gt;)&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In this case, the binder detects that the topic already exists. If the topic‚Äôs current partition size is less than what is requested, then the binder checks for a property &lt;code&gt;spring.cloud.stream.kafka.binder.autoAddPartitions&lt;/code&gt;. By default, this is set to &lt;code&gt;false&lt;/code&gt;. So, if the application has a need for increasing the partitions, this has to be explicitly set to &lt;code&gt;true&lt;/code&gt;. If it is set to &lt;code&gt;true&lt;/code&gt;, the provisioner will request the Kafka admin API to increase the number of partitions. If it is not set to true and the new requested number of partitions is higher than the existing number of partitions, then in the case of producers, the binder will complain that it cannot tolerate the lower number of partitions on the broker and throw a provisioning exception. If this happens, you have to either increase the partitions manually or set the &lt;code&gt;autoAddPartitions&lt;/code&gt; property to &lt;code&gt;true&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;One thing to note in particular here is that the binder does not allow you to decrease the number of Kafka topic partitions through Spring Cloud Stream.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Bear in mind that increasing or decreasing the partitions (using any mechanism) might break strict ordering within a partition (if that&amp;#8217;s a consideration), depending on your partitioning strategy (see below).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="selecting-a-partition"&gt;&lt;a class="anchor" href="#selecting-a-partition"&gt;&lt;/a&gt;Selecting a Partition&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Now that we understand how topics are partitioned, we need to discuss how to select a partition for a particular record.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;There are three mechanisms to select the partition:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="sect3"&gt;
&lt;h4 id="native-kafka-partition-selection"&gt;&lt;a class="anchor" href="#native-kafka-partition-selection"&gt;&lt;/a&gt;Native Kafka Partition Selection&lt;/h4&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;To use native partitioning, configure a custom Partitioner, either at the binder level, using the &lt;code&gt;spring.cloud.stream.kafka.binder.producer-properties.partitioner.class&lt;/code&gt; property
or at the binding level, using the
&lt;code&gt;spring.cloud.stream.kafka.bindings.&amp;lt;binding&amp;gt;.producer.configuration.partitioner.class&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect3"&gt;
&lt;h4 id="directly-setting-the-partition-header"&gt;&lt;a class="anchor" href="#directly-setting-the-partition-header"&gt;&lt;/a&gt;Directly setting the partition header&lt;/h4&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;When using the default Kafka Partitioner, the application can directly set the &lt;code&gt;KafkaHeaders.PARTITION_ID&lt;/code&gt;  header to the desired partition.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect3"&gt;
&lt;h4 id="spring-cloud-stream-partition-selection"&gt;&lt;a class="anchor" href="#spring-cloud-stream-partition-selection"&gt;&lt;/a&gt;Spring Cloud Stream Partition Selection&lt;/h4&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;When using Spring Cloud Stream partitioning, leave the kafka partitioner to use its default partitioner, which will simply use the partition set in the producer record by the binder. In the following sections, we will see details of this support provided by Spring Cloud Stream.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="how-does-a-spring-cloud-stream-producer-determine-which-partition-to-assign"&gt;&lt;a class="anchor" href="#how-does-a-spring-cloud-stream-producer-determine-which-partition-to-assign"&gt;&lt;/a&gt;How does a Spring Cloud Stream producer determine which partition to assign?&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;How is it that the producer assigns records to the right partitions using Spring Cloud Stream? What are the controls available for doing so in Spring Cloud Stream? The remainder of this blog will focus on these questions.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="sect3"&gt;
&lt;h4 id="deciding-on-a-partition-key"&gt;&lt;a class="anchor" href="#deciding-on-a-partition-key"&gt;&lt;/a&gt;Deciding on a partition key&lt;/h4&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Spring Cloud Stream provides two mechanisms for the application to decide on a partition key.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="sect4"&gt;
&lt;h5 id="1-partition-key-expression"&gt;&lt;a class="anchor" href="#1-partition-key-expression"&gt;&lt;/a&gt;1. Partition key expression&lt;/h5&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;A simple approach is to provide the partition key as a SpEL expression property. Here is an example.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&lt;code&gt;spring.cloud.stream.bindings.&amp;lt;binding-name&amp;gt;.producer.partition-key-expression: headers['partitionKey']&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Then your application, when publishing the message, can add a header called partitonKey. Spring Cloud Stream will use the value for this header when evaluating the above expression to assign a partition key. Here is an example producer code:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code&gt;@Bean
public Supplier&amp;lt;Message&amp;lt;?&amp;gt;&amp;gt; generate() {
  return () -&amp;gt; {
     String value = ‚Äúrandom payload‚Äù;
    	return MessageBuilder.withPayload(value)
           .setHeader("partitionKey", value.length() % 4)
           .build();
  };
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect4"&gt;
&lt;h5 id="2-partition-key-extractor-strategy"&gt;&lt;a class="anchor" href="#2-partition-key-extractor-strategy"&gt;&lt;/a&gt;2. Partition key extractor strategy&lt;/h5&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Spring Cloud Stream provides an API called PartitionKeyExtractorStrategy which has a single method to implement - &lt;code&gt;Object extractKey(Message&amp;lt;?&amp;gt; message)&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;You can implement this interface and configure it as a bean. Then provide a property &lt;code&gt;spring.cloud.stream.bindings.&amp;lt;binding-name&amp;gt;.producer.parition-key-extractor-name&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;And then provide the bean name.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;If you only have one such bean, then you can ignore providing this as a property. Spring Cloud Stream will simply pick this bean as the partition extractor strategy.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Setting a key using a partition key extractor strategy is the default mechanism. Spring Cloud Stream will only look for the partition key expression if an extractor strategy is not given.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Please bear in mind that this partition key we discussed here may not be the same as the ultimate partition the record will land upon. For that we need to use a partition selector that is using this key.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect3"&gt;
&lt;h4 id="selecting-the-actual-partition"&gt;&lt;a class="anchor" href="#selecting-the-actual-partition"&gt;&lt;/a&gt;Selecting the actual partition&lt;/h4&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;We selected a partition key, now how does it select the actual partition on Kafka topic?&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Ok, now we got Spring Cloud Stream to decide on a partition key to use. But, how about actually selecting the partition based on this key? Similar to the partition key selection options, Spring Cloud Stream provides two different mechanisms for selecting the partition with a given key.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="sect4"&gt;
&lt;h5 id="1-use-a-partition-selector-strategy"&gt;&lt;a class="anchor" href="#1-use-a-partition-selector-strategy"&gt;&lt;/a&gt;1. Use a Partition Selector Strategy`&lt;/h5&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Once again, this is a functional interface with a single method - &lt;code&gt;int selectPartition(Object key, int partitionCount)&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;You can implement this method and provide it as a bean. If you only have one such bean, you don‚Äôt need any additional property. If there are more than one, then you can define it per binding using the property &lt;code&gt;spring.cloud.stream.bindings.&amp;lt;binding-name&amp;gt;.producer.parition-selector-name&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect4"&gt;
&lt;h5 id="2-partition-selector-expression"&gt;&lt;a class="anchor" href="#2-partition-selector-expression"&gt;&lt;/a&gt;2. Partition Selector Expression&lt;/h5&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;If you don‚Äôt want to implement a partition selector strategy, you can also provide a SpEL expression that evaluates against the key.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;If neither of these options are provided, then Spring Cloud Stream will use a default Partition Selector Strategy which is based on taking the hashCode of the key and then doing a modulo operation with the total partition count on the topic. Unless you have sophisticated needs, this default strategy will work in most cases.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="why-is-the-binder-providing-two-different-abstractions"&gt;&lt;a class="anchor" href="#why-is-the-binder-providing-two-different-abstractions"&gt;&lt;/a&gt;Why is the binder providing two different abstractions?&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;You might be wondering why we have these two different abstractions. First a partition key and then a partition selector. Partition key could be anything - for example, it could be an integer, a string (maybe a text with arbitrary length) or some other type. Partition selector will select a key based on the partition key expression. The selector also makes sure that the partition selected is bound within the available number of partitions. The default implementation does it by doing a modulo division of the hash code of the partition key and the total number of partitions. For this reason, when you have partitioning use cases like these, you must specify the &lt;code&gt;partittionCount&lt;/code&gt; property on the producer. In summary, &lt;code&gt;PartitionKey&lt;/code&gt; is a piece of data used by PartitionSelector to select the actual partition.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Let‚Äôs take a concrete example. Assume that you are writing an application that deals with credit card transactions. This application uses the credit card number as the partition key - a long random number with x number of digits. Imagine that depending on the first 4 digits of the credit card, you want to send that transaction to a particular partition in the topic. How do you do that? First, you set your &lt;code&gt;partitionKeyExpression&lt;/code&gt; by parsing the card number to extract the first 4 digits (or provide a partition key extractor strategy). Then, you need to provide a partition selector strategy implementation in which, based on the key and the number of partitions, you select the key. If you don‚Äôt provide this or a partition key selector expression against the key, then the default partition selector strategy will select one for you. Say, your first 4 digits are 1234 and you have 10 partitions on the topic. Let‚Äôs say that the hash is computed as 1234 also. Then, this will land in partition &lt;code&gt;1234 % 10 = 4&lt;/code&gt;. If you rather want this transaction to come to partition 8 for whatever reason, then you have to explicitly implement that in partition selector strategy class or expression.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Following is a flow chart representation of how these two different layers fit together.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&lt;span class="image"&gt;&lt;img src="https://github.com/spring-cloud/spring-cloud-stream-binder-kafka/raw/gh-pages/images/kafka-producer-partitions-blog.png" alt="kafka producer partitions blog"&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="confusion-between-partition-key-and-the-message-key"&gt;&lt;a class="anchor" href="#confusion-between-partition-key-and-the-message-key"&gt;&lt;/a&gt;Confusion between partition key and the message key&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Sometimes it is confusing to think through partition keys and the actual message keys going down the wire through the actual Kafka topic to be used on the Kafka record as the key. It is done through a different mechanism. The above partition key and the selector simply ensures that a partition key is chosen and based on that partition key, an actual partition is selected on the Kafka topic. But, how do you send a key with the record when producing? Here again, you can choose from two options. One is simply to attach a header into the outgoing message. Here is an example.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code&gt;@Bean Supplier&amp;lt;Message&amp;lt;String&amp;gt;&amp;gt; process() {
   return () -&amp;gt; MessageBuilder.withPayload("foo")
     .setHeader(KafkaHeaders.MESSAGE_KEY, "bar".getBytes()) .build(); }&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;You can also use a message key SpEL expression on the Kafka binder as below.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&lt;code&gt;spring.cloud.stream.kafka.binder.messageKeyExpression: headers['messageKey']&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Then attach this header on the outgoing message.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="some-caveats-to-keep-in-mind"&gt;&lt;a class="anchor" href="#some-caveats-to-keep-in-mind"&gt;&lt;/a&gt;Some caveats to keep in mind&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;If you don‚Äôt provide a partition key expression or partition key extractor bean, then Spring Cloud Stream will completely stay out of the business of making any partition decision for you. In that case, if the topic has more than one partition, Kafka‚Äôs default partitioning mechanisms will be triggered. By default, Kafka uses a DefaultPartitioner, which if the message has a key (see above), then using the hash of this key for computing the partition. If the message does not have a key, then it will be assigned using a round robin strategy. Starting with Kafka client 2.4 onwards, there are some additional complexities to keep in mind. If the record doesn‚Äôt carry the partition information (the main discussion of this blog) or if the record is missing a key, then starting with Kafka 2.4, it will use sticky partitions instead of a round-robin strategy. In a nutshell, sticky partitions are used to minimize the latency by sticking the records to a partition or a group of partitions. For more information on sticky partitions, see KIP-480 &lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-480%3A+Sticky+Partitioner" class="bare"&gt;https://cwiki.apache.org/confluence/display/KAFKA/KIP-480%3A+Sticky+Partitioner&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="sect2"&gt;
&lt;h3 id="conclusion"&gt;&lt;a class="anchor" href="#conclusion"&gt;&lt;/a&gt;Conclusion&lt;/h3&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;In this blog, we discussed how Spring Cloud Stream can help with dealing with Kafka partitions when writing a producer based application. We saw a number of ways Spring Cloud Stream gives controls to the application developer to configure the various nuances of partitions. We saw the differences between partition key, partition selector and message key. We discussed how message keys can be added to a Kafka record. Finally, we looked at how Spring Cloud Stream producers can completely stay out of the partitioning business and let Kafka tackle it directly.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>This Week in Spring - February 2nd, 2020</title>
    <link rel="alternate" href="https://spring.io/blog/2021/02/02/this-week-in-spring-february-2nd-2020" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>Josh Long</name>
    </author>
    <id>tag:spring.io,2021-02-03:4351</id>
    <updated>2021-02-03T02:44:00Z</updated>
    <content type="html">&lt;p&gt;Hi, Spring fans! Welcome to another installment of &lt;em&gt;This Week in Spring&lt;/em&gt;! Can you believe we&amp;rsquo;re already square into the second month of 2021? We&amp;rsquo;re 1/12th of the way through the year already! IT&amp;rsquo;S ALL GOING SO QUICK! So, I won&amp;rsquo;t waste any further time, let&amp;rsquo;s get to the roundup! &lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;This is a fantastic video by the legendary Brian Sam Boden on &lt;a href="https://www.youtube.com/watch?v=XJoJCMfCSTk&amp;feature=emb_title"&gt;&lt;em&gt;building a Spring Boot REST API powered by Redis, with a React front end: Part 1&lt;/em&gt; &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://blogs.vmware.com/opensource/2021/02/02/2021-a-look-ahead-for-open-source-at-vmware/"&gt;2021: A Look Ahead for Open Source at VMware&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2021/01/28/a-bootiful-podcast-appdynamics-pavol-loffay"&gt;A Bootiful Podcast: Traceable&amp;rsquo;s Pavol Loffay, creator of the Hypertrace Java agent&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.infoq.com/news/2021/01/graalvm-21-jvm-java/"&gt;GraalVM 21.0 Introduces a JVM Written in Java&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://medium.com/sipios/handle-r2dbc-in-spring-projects-fa96e65ca24d"&gt;Handle R2DBC in Spring Projects, &lt;/a&gt; an article by Thibault MONEGIER du SORBIER&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.meetup.com/seajug/events/276135388/"&gt;I&amp;rsquo;ll be speaking at the Seattle JUG Meetup on February 16th, 2021&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://blogs.oracle.com/developers/new-year-goodies-oracle-jdbc-21100-on-maven-central"&gt;New Year Goodies - Oracle JDBC 21.1.0.0 on Maven Central | Oracle Developers Blog&lt;/a&gt;. I linked to this because, at the bottom of the blog, they also mention that people can expect the reactive Oracle R2DBC driver soon, too! Huzzah!&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.vinsguru.com/rsocket-load-balancing-client-side/"&gt;RSocket Load Balancing - Client Side by Vinsguru&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.infoq.com/articles/running-axon-server-docker-kubernetes/?itm_campaign=rightbar_v2&amp;itm_source=infoq&amp;itm_medium=articles_link&amp;itm_content=link_text"&gt;Running Axon Server in Docker and Kubernetes&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2021/01/27/spring-batch-on-kubernetes-efficient-batch-processing-at-scale"&gt;Spring Batch on Kubernetes: Efficient batch processing at scale&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2021/01/28/spring-cloud-2020-0-1-aka-ilford-is-available"&gt;Spring Cloud 2020.0.1 (aka Ilford) Is Available&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2021/02/01/spring-integration-aws-2-3-5-release-2-4-0-and-spring-cloud-stream-kinesis-binder-2-0-4-release-2-1-0-available"&gt;Spring Integration AWS 2.3.5.RELEASE &amp;amp; 2.4.0, and Spring Cloud Stream Kinesis Binder 2.0.4.RELEASE &amp;amp; 2.1.0 Available&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2021/02/01/ymnnalft-a-lightweight-sql-data-mapper-with-the-jdbctemplate"&gt;YMNNALFT: A lightweight SQL data mapper with the JdbcTemplate&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2021/01/27/ymnnalft-the-spring-utils-classes"&gt;YMNNALFT: The Spring Utils Classes&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://twitter.com/JavaAtMicrosoft/status/1354831588916305922"&gt;Last year Azure #Spring Cloud became Generally Available. Here&amp;rsquo;s what has changed since then! &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://twitter.com/JavaAtMicrosoft/status/1356334244008611840"&gt;Apple announced M1, an impl of AArch64. #OpenJDK was ready for it; had been for 5 years. However there&amp;rsquo;s a layer that‚Äôs specific to each OS-CPU combination. However there&amp;rsquo;s a layer that‚Äôs specific to each OS-CPU combination. We had volunteers: Microsoft and Azul, who worked together. Microsoft also ported to Win/AArch64 &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://twitter.com/VMware/status/1356739950620905472"&gt; Today, we‚Äôre excited to announce dates for VMware conferences slated for this year &amp;ndash; VMworld, CloudLIVE, Connect, and SpringOne! &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>Spring Integration AWS 2.3.5.RELEASE &amp; 2.4.0,  and Spring Cloud Stream Kinesis Binder 2.0.4.RELEASE &amp; 2.1.0 Available</title>
    <link rel="alternate" href="https://spring.io/blog/2021/02/01/spring-integration-aws-2-3-5-release-2-4-0-and-spring-cloud-stream-kinesis-binder-2-0-4-release-2-1-0-available" />
    <category term="releases" label="Releases" />
    <author>
      <name>Artem Bilan</name>
    </author>
    <id>tag:spring.io,2021-02-01:4350</id>
    <updated>2021-02-01T16:05:00Z</updated>
    <content type="html">&lt;div class="paragraph"&gt;
&lt;p&gt;Dear Spring Community,&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Today it&amp;#8217;s my pleasure to announce releases of Spring Integration for Amazon Web Services extension versions &lt;code&gt;2.3.5.RELEASE&lt;/code&gt; &amp;amp; &lt;code&gt;2.4.0&lt;/code&gt;, and Spring Cloud Stream Binder for AWS Kinesis versions &lt;code&gt;2.0.4.RELEASE&lt;/code&gt; &amp;amp; &lt;code&gt;2.1.0&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;These releases can be downloaded from Maven Central, JCenter:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code data-lang="groovy"&gt;compile "org.springframework.integration:spring-integration-aws:2.3.5.RELEASE"&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;If you don&amp;#8217;t use Kinesis Binder.
Or via Binder dependency:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="listingblock"&gt;
&lt;div class="content"&gt;
&lt;pre class="prettyprint highlight"&gt;&lt;code data-lang="groovy"&gt;compile "org.springframework.cloud:spring-cloud-stream-binder-kinesis:2.0.4.RELEASE"&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Mostly these versions have bug fixes and some community feedback refinements.
So, it is highly recommended to bump your projects to this latest versions.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;The new minor versions (&lt;code&gt;spring-integration-aws:2.4.0&lt;/code&gt; &amp;amp; &lt;code&gt;spring-cloud-stream-binder-kinesis:2.1.0&lt;/code&gt;) have the same fixes content, but with an upgrade to the latest Spring Integration and Spring Cloud Stream versions for compatibility with the latest Spring Boot and Spring Cloud, respectively.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Many thanks to everyone from the Community for all the feedback and contribution to these projects.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Any feedback is welcome via all the available communication channels!&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Spring Integration for AWS resources:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&lt;a href="https://github.com/spring-projects/spring-integration-aws"&gt;Project Page&lt;/a&gt; | &lt;a href="https://github.com/spring-projects/spring-integration/blob/master/CONTRIBUTING.adoc"&gt;Contributing&lt;/a&gt; | &lt;a href="http://stackoverflow.com/questions/tagged/spring-integration"&gt;Help&lt;/a&gt; | &lt;a href="https://gitter.im/spring-projects/spring-integration"&gt;Chat&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;Spring Cloud Stream Binder for AWS Kinesis resources:&lt;/p&gt;
&lt;/div&gt;
&lt;div class="paragraph"&gt;
&lt;p&gt;&lt;a href="https://github.com/spring-cloud/spring-cloud-stream-binder-aws-kinesis"&gt;Project Page&lt;/a&gt; | &lt;a href="https://github.com/spring-cloud/spring-cloud-stream-binder-aws-kinesis/blob/master/spring-cloud-stream-binder-kinesis-docs/src/main/asciidoc/contributing.adoc"&gt;Contributing&lt;/a&gt; | &lt;a href="http://stackoverflow.com/questions/tagged/spring-cloud-stream"&gt;Help&lt;/a&gt; | &lt;a href="https://gitter.im/spring-projects/spring-cloud-stream"&gt;Chat&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>YMNNALFT: A lightweight SQL data mapper with the JdbcTemplate</title>
    <link rel="alternate" href="https://spring.io/blog/2021/02/01/ymnnalft-a-lightweight-sql-data-mapper-with-the-jdbctemplate" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>Josh Long</name>
    </author>
    <id>tag:spring.io,2020-12-30:4324</id>
    <updated>2021-02-01T11:00:00Z</updated>
    <content type="html">&lt;p&gt;Welcome to another installment of &lt;em&gt;You May Not Need Another Library For That&lt;/em&gt; (YMNNALFT)! I&amp;rsquo;ve spent a lot of time since 2016 illuminating (or trying to, anyway!) some of the more enormous opportunities in the Spring ecosystem in &lt;a href="http://bit.ly/spring-tips-playlist"&gt;my Spring Tips videos&lt;/a&gt;. Today, however, I come to you in a different spirit, wanting to focus on the little, sometimes hidden, gems that do fantastic things and that might spare you an additional third-party dependency and its implied complexity. &lt;/p&gt;
&lt;p&gt;I think the first use I had for Spring, more than 15 years ago, was the &lt;code&gt;JdbcTemplate&lt;/code&gt;, which eliminated the eye-watering and verbose work of using JDBC directly. As you might know, JDBC stands for &amp;ldquo;Just Don&amp;rsquo;t Break, Compiler!&amp;rdquo; and was designed to test the JVM limit of 65535 bytes of bytecode per method by providing an API that consistently requires more lines of code than that to do even basic things. &lt;/p&gt;
&lt;p&gt;Thus just in. I&amp;rsquo;m being told that JDBC is, in fact, the Java Database Connectivity API. Moving on&amp;hellip; &lt;/p&gt;
&lt;p&gt;I couldn&amp;rsquo;t use Spring as a framework in the project at the time, but I &lt;em&gt;could&lt;/em&gt; bring in Spring as a sort of library. I brought it in initially to get access to the &lt;code&gt;JdbcTemplate&lt;/code&gt;, and the concept of the various &lt;code&gt;*Template&lt;/code&gt; objects as a whole. &lt;/p&gt;
&lt;p&gt;A template object is an excellent example of the inversion-of-control principle. You let the template object do 90% of the work and provide it with a callback to be invoked when the template needs your input on something. Templates invert the application flow; they do the tedious stuff and then involve you only when it&amp;rsquo;s time to do the thing you want to do. They&amp;rsquo;re kind of like &lt;em&gt;mini-frameworks&lt;/em&gt;. &lt;/p&gt;
&lt;p&gt;The &lt;code&gt;JdbcTemplate&lt;/code&gt; is one of the best-known templates in the Java ecosystem, and for a good reason. JDBC is a low-level API in the Java ecosystem for working with SQL databases. It&amp;rsquo;s powerful, and it has dominated for &lt;em&gt;decades&lt;/em&gt;. But it is, at the end of the day, &lt;em&gt;very&lt;/em&gt; low level. You&amp;rsquo;re not going to get very far writing this code yourself. &lt;/p&gt;
&lt;p&gt;The alternatives were brittle (at the time) technologies like Hibernate, Apache OJB, any of the various, mildly incompatible JDO implementations, iBatis, or - &lt;em&gt;gasp!&lt;/em&gt; - EJB 1.x or 2.x persistent entity beans. Most of these were way too top-heavy for the work I was trying to do. I loved iBatis (and continue to love its &lt;a href="http://mybatis.org/spring-boot-starter/mybatis-spring-boot-autoconfigure/"&gt;successor MyBatis&lt;/a&gt;), but I found I could get far with just the &lt;code&gt;JdbcTemplate&lt;/code&gt;. &lt;/p&gt;
&lt;p&gt;The &lt;code&gt;JdbcTemplate&lt;/code&gt; is part of a rich class arrangement and various abstractions for working with SQL databases. Nowadays, there&amp;rsquo;s even a non-blocking, reactive alternative to JDBC available to the Spring developer: &lt;a href="https://R2DBC.io"&gt;R2DBC&lt;/a&gt;. Most data access logic today uses JDBC (indirectly, if nothing else), alas, so let&amp;rsquo;s look at an example of that. &lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
  &lt;p&gt;JDBC on &lt;a href="http://start.spring.io"&gt;the Spring Initializr&lt;/a&gt; - &lt;code&gt;org.springframework.boot&lt;/code&gt; : &lt;code&gt;spring-boot-starter-jdbc&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
  &lt;li&gt;
  &lt;p&gt;H2 on &lt;a href="http://start.spring.io"&gt;the Spring Initializr&lt;/a&gt; - &lt;code&gt;com.h2database&lt;/code&gt; : &lt;code&gt;h2&lt;/code&gt; &lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here&amp;rsquo;s the code:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint java"&gt;package bootiful.data;&#xD;
&#xD;
import lombok.SneakyThrows;&#xD;
import org.springframework.boot.SpringApplication;&#xD;
import org.springframework.boot.autoconfigure.SpringBootApplication;&#xD;
import org.springframework.boot.context.event.ApplicationReadyEvent;&#xD;
import org.springframework.context.ApplicationListener;&#xD;
import org.springframework.context.annotation.Bean;&#xD;
import org.springframework.core.io.ClassPathResource;&#xD;
import org.springframework.core.io.Resource;&#xD;
import org.springframework.jdbc.core.JdbcTemplate;&#xD;
import org.springframework.jdbc.datasource.embedded.EmbeddedDatabaseBuilder;&#xD;
import org.springframework.jdbc.datasource.embedded.EmbeddedDatabaseType;&#xD;
import org.springframework.util.FileCopyUtils;&#xD;
&#xD;
import javax.sql.DataSource;&#xD;
import java.io.InputStreamReader;&#xD;
import java.io.Reader;&#xD;
import java.util.List;&#xD;
&#xD;
@SpringBootApplication&#xD;
public class BootifulApplication {&#xD;
&#xD;
	public static void main(String[] args) {&#xD;
		SpringApplication.run(BootifulApplication.class, args);&#xD;
	}&#xD;
&#xD;
	@Bean&#xD;
	DataSource dataSource() {&#xD;
		return new EmbeddedDatabaseBuilder().setType(EmbeddedDatabaseType.H2).build();&#xD;
	}&#xD;
&#xD;
	@SneakyThrows&#xD;
	private String loadSql() {&#xD;
		Resource resource = new ClassPathResource(&amp;quot;/initialization.sql&amp;quot;);&#xD;
		try (Reader r = new InputStreamReader(resource.getInputStream())) {&#xD;
			return FileCopyUtils.copyToString(r);&#xD;
		}&#xD;
	}&#xD;
&#xD;
	@Bean&#xD;
	ApplicationListener&amp;lt;ApplicationReadyEvent&amp;gt; ready(DataSource dataSource) {&#xD;
		return event -&amp;gt; {&#xD;
			String sql = loadSql();&#xD;
			String[] names = new String[] { &amp;quot;Spencer&amp;quot;, &amp;quot;Violetta&amp;quot;, &amp;quot;Madhura&amp;quot;, &amp;quot;Yuxin&amp;quot;, &amp;quot;St√©phane&amp;quot;, &amp;quot;Dr. Syer&amp;quot; };&#xD;
			JdbcTemplate template = new JdbcTemplate(dataSource);&#xD;
			template.execute(sql);&#xD;
			for (var name : names) {&#xD;
				template.update(&amp;quot;insert into CUSTOMER(name) values(?)&amp;quot;, name);&#xD;
			}&#xD;
			List&amp;lt;Customer&amp;gt; results = template.query(&amp;quot;select * from CUSTOMER&amp;quot;,&#xD;
					(resultSet, i) -&amp;gt; new Customer(resultSet.getInt(&amp;quot;id&amp;quot;), resultSet.getString(&amp;quot;name&amp;quot;)));&#xD;
			results.forEach(System.out::println);&#xD;
		};&#xD;
	}&#xD;
&#xD;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you don&amp;rsquo;t mind rolling up your sleeves and slinging a little SQL (and why would you? SQL is &lt;em&gt;awesome&lt;/em&gt;!), then you&amp;rsquo;ll feel right at home using the &lt;code&gt;JdbcTemplate&lt;/code&gt; and the various commands classes in the JDBC module. If not, Spring continues to meet you where you today with rich integrations for JDBC-centric data access technologies like JOOQ, Hibernate, JPA, MyBatis, Spring Data JPA, Spring Data JDBC, and a slew of other options. &lt;/p&gt;
&lt;p&gt;Did you like this gem at a glance approach? Did you learn anything? As always, I&amp;rsquo;m keen on hearing from you, so &lt;a href="http://twitter.com/starbuxman"&gt;please sound off on Twitter (@starbuxman) &lt;/a&gt;! I&amp;rsquo;ll be back with another installment of &lt;em&gt;YMNNALFT&lt;/em&gt;, so be sure not to miss that. &lt;/p&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>A Bootiful Podcast: Hypertrace Java Agent creator Pavol Loffay</title>
    <link rel="alternate" href="https://spring.io/blog/2021/01/28/a-bootiful-podcast-hypertrace-java-agent-creator-pavol-loffay" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>Josh Long</name>
    </author>
    <id>tag:spring.io,2021-01-29:4349</id>
    <updated>2021-01-29T01:13:00Z</updated>
    <content type="html">&lt;p&gt;Hi, Spring fans! In this episode &lt;a href="http://twitter.com/starbuxman"&gt;Josh Long (@starbuxman)&lt;/a&gt; talks to Hypertrace Java Agent creator &lt;a href="http://twitter.com/ploffay"&gt;Pavol Loffay (@ploffay)&lt;/a&gt; about telemetry, observability, and more. &lt;/p&gt;
&lt;iframe title="Hypertrace Java Agent creator Pavol Loffay" height="122" width="100%" style="border: none;" scrolling="no" data-name="pb-iframe-player" src="https://www.podbean.com/media/player/vm8cv-f8f4ea?from=pb6admin&amp;download=1&amp;version=1&amp;auto=0&amp;share=1&amp;download=1&amp;rtl=0&amp;fonts=Helvetica&amp;skin=1&amp;pfauth=&amp;btn-skin=107"&gt;&lt;/iframe&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>Spring Cloud 2020.0.1 (aka Ilford) Is Available</title>
    <link rel="alternate" href="https://spring.io/blog/2021/01/28/spring-cloud-2020-0-1-aka-ilford-is-available" />
    <category term="releases" label="Releases" />
    <author>
      <name>Spencer Gibb</name>
    </author>
    <id>tag:spring.io,2021-01-28:4348</id>
    <updated>2021-01-28T20:38:00Z</updated>
    <content type="html">&lt;p&gt;On behalf of the community, I am pleased to announce that Service Release 1 of the &lt;a href="https://cloud.spring.io"&gt;Spring Cloud 2020.0&lt;/a&gt; Release Train (2020.0.1) is available today. The release can be found in &lt;a href="https://repo1.maven.org/maven2/org/springframework/cloud/spring-cloud-dependencies/2020.0.1/"&gt;Maven Central&lt;/a&gt;. You can check out the 2020.0 &lt;a href="https://github.com/spring-projects/spring-cloud/wiki/Spring-Cloud-2020.0-Release-Notes"&gt;release notes for more information&lt;/a&gt;.&lt;/p&gt;&lt;h2&gt;&lt;a href="#notable-changes-in-the-2020-0-0-release-train" class="anchor" name="notable-changes-in-the-2020-0-0-release-train"&gt;&lt;/a&gt;Notable Changes in the 2020.0.0 Release Train&lt;/h2&gt;
&lt;p&gt;This release was primarliy for bug fixes and dependency upgrades.&lt;/p&gt;
&lt;p&gt;See &lt;a href="https://github.com/spring-cloud/spring-cloud-release/wiki/Spring-Cloud-2020.0-Release-Notes#known-issues"&gt;this page&lt;/a&gt; for a list of Known Issues.&lt;/p&gt;
&lt;p&gt;See the &lt;a href="https://github.com/spring-cloud/spring-cloud-release/wiki/Spring-Cloud-2020.0-Release-Notes#breaking-changes"&gt;wiki&lt;/a&gt; for a list of all breaking changes in this release train.&lt;/p&gt;
&lt;p&gt;See all of the included issues and pull requests at the &lt;a href="https://github.com/orgs/spring-cloud/projects/52"&gt;Github project&lt;/a&gt;.&lt;/p&gt;&lt;h3&gt;&lt;a href="#spring-cloud-config" class="anchor" name="spring-cloud-config"&gt;&lt;/a&gt;Spring Cloud Config&lt;/h3&gt;
&lt;p&gt;All of the &lt;a href="https://github.com/spring-cloud/spring-cloud-release/wiki/Spring-Cloud-2020.0-Release-Notes#known-issues"&gt;known issues&lt;/a&gt; have been fixed.&lt;/p&gt;&lt;h3&gt;&lt;a href="#spring-cloud-consul" class="anchor" name="spring-cloud-consul"&gt;&lt;/a&gt;Spring Cloud Consul&lt;/h3&gt;
&lt;p&gt;A new &lt;a href="https://github.com/spring-cloud/spring-cloud-release/wiki/Spring-Cloud-2020.0-Release-Notes#known-issues"&gt;known issue&lt;/a&gt; have been found, where the &lt;code&gt;spring.config.import=consul:&lt;/code&gt; does not support retry.&lt;/p&gt;
&lt;p&gt;The issue with improper order of contexts in the Config module has been fixed.&lt;/p&gt;&lt;h3&gt;&lt;a href="#spring-cloud-zookeeper" class="anchor" name="spring-cloud-zookeeper"&gt;&lt;/a&gt;Spring Cloud Zookeeper&lt;/h3&gt;
&lt;p&gt;The issue with improper order of contexts in the Config module has been fixed.&lt;/p&gt;
&lt;hr/&gt;
&lt;p&gt;The following modules were updated as part of 2020.0.0:&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Module &lt;/th&gt;
      &lt;th&gt;Version &lt;/th&gt;
      &lt;th&gt;Issues&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Circuitbreaker &lt;/td&gt;
      &lt;td&gt;2.0.0 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Contract &lt;/td&gt;
      &lt;td&gt;3.0.1 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Kubernetes &lt;/td&gt;
      &lt;td&gt;2.0.1 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Commons &lt;/td&gt;
      &lt;td&gt;3.0.1 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Openfeign &lt;/td&gt;
      &lt;td&gt;3.0.1 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Cloudfoundry &lt;/td&gt;
      &lt;td&gt;3.0.0 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Bus &lt;/td&gt;
      &lt;td&gt;3.0.1 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Cli &lt;/td&gt;
      &lt;td&gt;3.0.1 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Zookeeper &lt;/td&gt;
      &lt;td&gt;3.0.1 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Sleuth &lt;/td&gt;
      &lt;td&gt;3.0.1 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Consul &lt;/td&gt;
      &lt;td&gt;3.0.1 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Starter Build &lt;/td&gt;
      &lt;td&gt;2020.0.1 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Gateway &lt;/td&gt;
      &lt;td&gt;3.0.1 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Netflix &lt;/td&gt;
      &lt;td&gt;3.0.1 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Vault &lt;/td&gt;
      &lt;td&gt;3.0.1 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Config &lt;/td&gt;
      &lt;td&gt;3.0.2 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Spring Cloud Task &lt;/td&gt;
      &lt;td&gt;2.3.0 &lt;/td&gt;
      &lt;td&gt;&amp;nbsp;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;As always, we welcome feedback on &lt;a href="https://github.com/spring-cloud/"&gt;GitHub&lt;/a&gt;, on &lt;a href="https://gitter.im/spring-cloud/spring-cloud"&gt;Gitter&lt;/a&gt;, on &lt;a href="https://stackoverflow.com/questions/tagged/spring-cloud"&gt;Stack Overflow&lt;/a&gt;, or on &lt;a href="https://twitter.com/SpringCloud"&gt;Twitter&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To get started with Maven with a BOM (dependency management only):&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint xml"&gt;&amp;lt;dependencyManagement&amp;gt;&#xD;
    &amp;lt;dependencies&amp;gt;&#xD;
        &amp;lt;dependency&amp;gt;&#xD;
            &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;&#xD;
            &amp;lt;artifactId&amp;gt;spring-cloud-dependencies&amp;lt;/artifactId&amp;gt;&#xD;
            &amp;lt;version&amp;gt;2020.0.1&amp;lt;/version&amp;gt;&#xD;
            &amp;lt;type&amp;gt;pom&amp;lt;/type&amp;gt;&#xD;
            &amp;lt;scope&amp;gt;import&amp;lt;/scope&amp;gt;&#xD;
        &amp;lt;/dependency&amp;gt;&#xD;
    &amp;lt;/dependencies&amp;gt;&#xD;
&amp;lt;/dependencyManagement&amp;gt;&#xD;
&amp;lt;dependencies&amp;gt;&#xD;
    &amp;lt;dependency&amp;gt;&#xD;
        &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;&#xD;
        &amp;lt;artifactId&amp;gt;spring-cloud-starter-config&amp;lt;/artifactId&amp;gt;&#xD;
    &amp;lt;/dependency&amp;gt;&#xD;
    &amp;lt;dependency&amp;gt;&#xD;
        &amp;lt;groupId&amp;gt;org.springframework.cloud&amp;lt;/groupId&amp;gt;&#xD;
        &amp;lt;artifactId&amp;gt;spring-cloud-starter-netflix-eureka-client&amp;lt;/artifactId&amp;gt;&#xD;
    &amp;lt;/dependency&amp;gt;&#xD;
    ...&#xD;
&amp;lt;/dependencies&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;or with Gradle:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint groovy"&gt;buildscript {&#xD;
  dependencies {&#xD;
    classpath &amp;quot;io.spring.gradle:dependency-management-plugin:1.0.11.RELEASE&amp;quot;&#xD;
  }&#xD;
}&#xD;
&#xD;
apply plugin: &amp;quot;io.spring.dependency-management&amp;quot;&#xD;
&#xD;
dependencyManagement {&#xD;
  imports {&#xD;
    mavenBom &amp;#39;org.springframework.cloud:spring-cloud-dependencies:2020.0.1&amp;#39;&#xD;
  }&#xD;
}&#xD;
&#xD;
dependencies {&#xD;
  compile &amp;#39;org.springframework.cloud:spring-cloud-starter-config&amp;#39;&#xD;
  compile &amp;#39;org.springframework.cloud:spring-cloud-starter-netflix-eureka-client&amp;#39;&#xD;
  //...&#xD;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>Spring Batch on Kubernetes: Efficient batch processing at scale</title>
    <link rel="alternate" href="https://spring.io/blog/2021/01/27/spring-batch-on-kubernetes-efficient-batch-processing-at-scale" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>Mahmoud Ben Hassine</name>
    </author>
    <id>tag:spring.io,2021-01-13:4332</id>
    <updated>2021-01-27T23:00:00Z</updated>
    <content type="html">&lt;h2&gt;&lt;a href="#introduction" class="anchor" name="introduction"&gt;&lt;/a&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Batch processing has been a challenging area of computer science since its inception in the early days of punch cards and magnetic tapes. Nowadays, the modern cloud computing era comes with a whole new set of challenges for how to develop and operate batch workload efficiently in a cloud environment. In this blog post, I introduce some of the challenges a batch developer or architect may face when designing and running batch applications at scale and show how Spring Batch, Spring Boot and Kubernetes can tremendously simplify this task.&lt;/p&gt;&lt;h2&gt;&lt;a href="#challenges-of-designing-and-running-batch-workloads-in-the-cloud" class="anchor" name="challenges-of-designing-and-running-batch-workloads-in-the-cloud"&gt;&lt;/a&gt;Challenges of Designing and Running Batch Workloads in the Cloud&lt;/h2&gt;
&lt;p&gt;Designing cloud-native batch applications might seem easy compared to web applications, but this is not true. Batch developers face many challenges.&lt;/p&gt;&lt;h4&gt;&lt;a href="#1-fault-tolerance" class="anchor" name="1-fault-tolerance"&gt;&lt;/a&gt;1. Fault Tolerance&lt;/h4&gt;
&lt;p&gt;Batch processes typically interact with other services (such as databases, messages brokers, web services, and others) which are, by nature, flaky in cloud environments. Moreover, even the nodes on which those processes are run can die at any time and be replaced with healthy nodes. Cloud native batch applications should be designed in a fault-tolerant way.&lt;/p&gt;&lt;h4&gt;&lt;a href="#2-robustness" class="anchor" name="2-robustness"&gt;&lt;/a&gt;2. Robustness&lt;/h4&gt;
&lt;p&gt;It is not uncommon that the human error of running a batch job twice has some big financial consequences (such as what happened to &lt;a href="https://www.deseret.com/2000/8/29/19526136/oops-walgreen-accidentally-bills-credit-card-customers-twice"&gt;Walgreens&lt;/a&gt;, &lt;a href="https://www.smh.com.au/national/anzs-45m-bank-bungle-20060519-gdnksi.html"&gt;ANZ Bank&lt;/a&gt;, and &lt;a href="https://www.computerweekly.com/news/2240042675/NatWest-in-double-debit-error"&gt;NatWest&lt;/a&gt;, to name a few). Moreover, some platforms, such as Kubernetes, have some known limitations about the eventuality of &lt;a href="https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/#cron-job-limitations"&gt;running the same job twice&lt;/a&gt;. A cloud native batch application should be ready to deal with this kind of issues by design.&lt;/p&gt;&lt;h4&gt;&lt;a href="#3-cost-efficiency" class="anchor" name="3-cost-efficiency"&gt;&lt;/a&gt;3. Cost Efficiency&lt;/h4&gt;
&lt;p&gt;Cloud infrastructures are billed by cpu/memory/bandwidth usage. In case of failure, It would be inefficient to not be able to restart a job from where it left off and &amp;ldquo;lose&amp;rdquo; the cpu/memory/bandwidth usage of the previous run (and hence be billed twice or more!).&lt;/p&gt;&lt;h4&gt;&lt;a href="#4-observability" class="anchor" name="4-observability"&gt;&lt;/a&gt;4. Observability&lt;/h4&gt;
&lt;p&gt;Any modern batch architecture should be able to know at any point in time some key metrics, including:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;What jobs are currently running?&lt;/li&gt;
  &lt;li&gt;Which jobs have failed, if any?&lt;/li&gt;
  &lt;li&gt;Other questions about how things are going.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Being able to have these KPIs at a glance on a dashboard is vital for efficient operations.&lt;/p&gt;&lt;h4&gt;&lt;a href="#5-scalability" class="anchor" name="5-scalability"&gt;&lt;/a&gt;5. Scalability&lt;/h4&gt;
&lt;p&gt;We are dealing with an unprecedented amounts of data, which is impossible to handle on a single machine any more. Correctly processing large volumes of distributed data is probably the most challenging point. Cloud-native batch applications should be scalable by design.&lt;/p&gt;
&lt;p&gt;All these aspects should be taken into consideration when designing and developing cloud-native batch applications. This is a considerable amount of work on the developer&amp;rsquo;s side. Spring Batch takes care of most of these issues. I explain the details in the next section.&lt;/p&gt;&lt;h2&gt;&lt;a href="#how-does-spring-batch-make-a-batch-developer-rsquo-s-life-easier" class="anchor" name="how-does-spring-batch-make-a-batch-developer-rsquo-s-life-easier"&gt;&lt;/a&gt;How does Spring Batch Make a Batch Developer&amp;rsquo;s Life easier?&lt;/h2&gt;
&lt;p&gt;Spring Batch is the de facto batch processing framework on the JVM. Entire books have been written on the rich feature set provided by Spring Batch, but I would like to highlight the most relevant features that address the previously mentioned challenges in the context of cloud-native development:&lt;/p&gt;&lt;h4&gt;&lt;a href="#1-fault-tolerance" class="anchor" name="1-fault-tolerance"&gt;&lt;/a&gt;1. Fault Tolerance&lt;/h4&gt;
&lt;p&gt;Spring Batch provides fault-tolerance feature, such as transaction management and skip and retry mechanisms, which are useful when batch jobs interact with flaky services in a cloud environment.&lt;/p&gt;&lt;h4&gt;&lt;a href="#2-robustness" class="anchor" name="2-robustness"&gt;&lt;/a&gt;2. Robustness&lt;/h4&gt;
&lt;p&gt;Spring Batch uses a centralized transactional job repository, which prevents duplicate job executions. By design, human errors and platform limitations that may lead to running the same job twice are impossible.&lt;/p&gt;&lt;h4&gt;&lt;a href="#3-cost-efficiency" class="anchor" name="3-cost-efficiency"&gt;&lt;/a&gt;3. Cost Efficiency&lt;/h4&gt;
&lt;p&gt;Spring Batch jobs maintain their state in an external database, which makes it possible to restart failed jobs where they left off. This is cost effective, compared to other solutions that would redo the work from the beginning and, hence, would be billed twice or more!&lt;/p&gt;&lt;h4&gt;&lt;a href="#4-observability" class="anchor" name="4-observability"&gt;&lt;/a&gt;4. Observability&lt;/h4&gt;
&lt;p&gt;Spring Batch provides integration with &lt;a href="https://micrometer.io"&gt;Micrometer&lt;/a&gt;, which is key in terms of observability. A Spring Batch-based batch infrastructure provides key metrics, such as the currently active jobs, read/write rates, failed jobs, and others. It can even be extended with custom metrics.&lt;/p&gt;&lt;h4&gt;&lt;a href="#5-scalability" class="anchor" name="5-scalability"&gt;&lt;/a&gt;5. Scalability&lt;/h4&gt;
&lt;p&gt;As already mentioned, Spring Batch jobs maintain their state in an external database. As a result, they are stateless processes from the &lt;a href="https://12factor.net"&gt;12 factors&lt;/a&gt; methodology point of view. This stateless nature makes them suitable to be containerized and executed in cloud environments in a scalable way. Moreover, Spring Batch provides several vertical and horizontal scaling techniques, such as multi-threaded steps and remote partitioning/chunking of data, to scale batch jobs in an efficient way.&lt;/p&gt;
&lt;p&gt;Spring Batch provides other features, but the ones mentioned above are very helpful when designing and developing cloud-native batch processes.&lt;/p&gt;&lt;h2&gt;&lt;a href="#how-does-kubernetes-make-the-batch-operator-rsquo-s-life-easier" class="anchor" name="how-does-kubernetes-make-the-batch-operator-rsquo-s-life-easier"&gt;&lt;/a&gt;How Does Kubernetes Make the Batch Operator&amp;rsquo;s Life Easier?&lt;/h2&gt;
&lt;p&gt;Kubernetes is the de facto container orchestration platform for the cloud. Operating a batch infrastructure at scale is far from being a trivial task, and Kubernetes really is a game changer in this space. Before the cloud era, in one of my previous jobs, I played the role of a batch operator and I had to manage a cluster of 4 machines dedicated to batch jobs. Here are some of the tasks I had to either do manually or find a way to automate with (bash!) scripts:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;ssh into each machine to check which jobs are currently running&lt;/li&gt;
  &lt;li&gt;ssh into each machine to collect the logs of failed jobs&lt;/li&gt;
  &lt;li&gt;ssh into each machine to upgrade job versions or update their configuration&lt;/li&gt;
  &lt;li&gt;ssh into each machine to kill hanging jobs and restart them&lt;/li&gt;
  &lt;li&gt;ssh into each machine to edit/update the crontab file for job scheduling&lt;/li&gt;
  &lt;li&gt;Many other similar tasks..&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All these tasks are obviously inefficient and error prone, leaving four dedicated machines under-utilized due to poor resource management. If you are still doing such tasks in 2021 (either manually or via scripts), I believe it&amp;rsquo;s a good time to think about migrating your batch infrastructure to Kubernetes. The reason is that Kubernetes lets you do all these tasks with a &lt;strong&gt;single&lt;/strong&gt; command against the &lt;strong&gt;entire&lt;/strong&gt; cluster, and this is a &lt;strong&gt;huge&lt;/strong&gt; difference from an operational point of view. Moving to Kubernetes lets you:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Ask the entire cluster about currently running jobs with a single command&lt;/li&gt;
  &lt;li&gt;Submit/schedule jobs without having to know on which node they will run&lt;/li&gt;
  &lt;li&gt;Update job definitions transparently&lt;/li&gt;
  &lt;li&gt;Automatically run jobs to completion (a Kubernetes job creates one or more pods and ensures that a specified number of them terminate successfully)&lt;/li&gt;
  &lt;li&gt;Optimize the usage of cluster&amp;rsquo;s resources (Kubernetes plays Tetris with the cluster&amp;rsquo;s machines) and hence optimize the bills!&lt;/li&gt;
  &lt;li&gt;Use many other interesting features&lt;/li&gt;
&lt;/ul&gt;&lt;h2&gt;&lt;a href="#spring-batch-on-kubernetes-a-perfect-match-in-action" class="anchor" name="spring-batch-on-kubernetes-a-perfect-match-in-action"&gt;&lt;/a&gt;Spring Batch on Kubernetes: a perfect match, in action&lt;/h2&gt;
&lt;p&gt;In this section, I take the same job developed in Spring Batch&amp;rsquo;s &lt;a href="https://spring.io/guides/gs/batch-processing"&gt;getting started guide&lt;/a&gt; (which is a data ingestion job that loads some person data from a CSV file into a relational database table), containerize it, and deploy it on Kubernetes. If you want to go a step further by wrapping this job in a Spring Cloud Task and deploying it in a Spring Cloud Data Flow server, see &lt;a href="https://dataflow.spring.io/docs/batch-developer-guides/batch/data-flow-spring-batch"&gt;Deploy a Spring Batch application by Using Data Flow&lt;/a&gt;.&lt;/p&gt;&lt;h3&gt;&lt;a href="#1-set-up-a-database-server" class="anchor" name="1-set-up-a-database-server"&gt;&lt;/a&gt;1. Set up a Database Server&lt;/h3&gt;
&lt;p&gt;I use a MySQL database to store Spring Batch metadata. The database lives outside the Kubernetes cluster, and this is on purpose. The reason is to mimic a realistic migration path, where only stateless workloads are migrated to Kubernetes in a first step. For many companies, migrating databases to Kubernetes is not an option yet (and this is a reasonable decision). To start the database server, run the following commands:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint"&gt;$ git clone git@github.com:benas/spring-batch-lab.git&#xD;
$ cd blog/spring-batch-kubernetes&#xD;
$ docker-compose -f src/docker/docker-compose.yml up
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will create a MySQL container pre-populated with &lt;a href="https://github.com/spring-projects/spring-batch/blob/master/spring-batch-core/src/main/resources/org/springframework/batch/core/schema-mysql.sql"&gt;Spring Batch&amp;rsquo;s technical tables&lt;/a&gt; as well as the &lt;a href="https://github.com/spring-guides/gs-batch-processing/blob/master/initial/src/main/resources/schema-all.sql"&gt;business table, &lt;code&gt;PEOPLE&lt;/code&gt;&lt;/a&gt;. We can check this, as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint"&gt;$ docker exec -it mysql bash&#xD;
root@0a6596feb06d:/# mysql -u root test -p # the root password is &amp;quot;root&amp;quot;&#xD;
Enter password:&#xD;
Reading table information for completion of table and column names&#xD;
You can turn off this feature to get a quicker startup with -A&#xD;
&#xD;
Welcome to the MySQL monitor.  Commands end with ; or \g.&#xD;
Your MySQL connection id is 8&#xD;
Server version: 8.0.21 MySQL Community Server - GPL&#xD;
&#xD;
Copyright (c) 2000, 2020, Oracle and/or its affiliates. All rights reserved.&#xD;
&#xD;
Oracle is a registered trademark of Oracle Corporation and/or its&#xD;
affiliates. Other names may be trademarks of their respective&#xD;
owners.&#xD;
&#xD;
Type &amp;#39;help;&amp;#39; or &amp;#39;\h&amp;#39; for help. Type &amp;#39;\c&amp;#39; to clear the current input statement.&#xD;
mysql&amp;gt; show tables;&#xD;
+------------------------------+&#xD;
| Tables_in_test               |&#xD;
+------------------------------+&#xD;
| BATCH_JOB_EXECUTION          |&#xD;
| BATCH_JOB_EXECUTION_CONTEXT  |&#xD;
| BATCH_JOB_EXECUTION_PARAMS   |&#xD;
| BATCH_JOB_EXECUTION_SEQ      |&#xD;
| BATCH_JOB_INSTANCE           |&#xD;
| BATCH_JOB_SEQ                |&#xD;
| BATCH_STEP_EXECUTION         |&#xD;
| BATCH_STEP_EXECUTION_CONTEXT |&#xD;
| BATCH_STEP_EXECUTION_SEQ     |&#xD;
| PEOPLE                       |&#xD;
+------------------------------+&#xD;
10 rows in set (0.01 sec)&#xD;
&#xD;
mysql&amp;gt; select * from PEOPLE;&#xD;
Empty set (0.00 sec)
&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt;&lt;a href="#2-create-a-bootiful-containerized-spring-batch-job" class="anchor" name="2-create-a-bootiful-containerized-spring-batch-job"&gt;&lt;/a&gt;2. Create a Bootiful, Containerized Spring Batch Job&lt;/h3&gt;
&lt;p&gt;Go to &lt;a href="https://start.spring.io"&gt;start.spring.io&lt;/a&gt; and generate a project with the following dependencies: Spring Batch and the MySQL driver. You can use this &lt;a href="https://start.spring.io/#!type=maven-project&amp;language=java&amp;platformVersion=2.4.1.RELEASE&amp;packaging=jar&amp;jvmVersion=1.8&amp;groupId=com.example&amp;artifactId=demo&amp;name=demo&amp;description=Demo%20project%20for%20Spring%20Boot&amp;packageName=com.example.demo&amp;dependencies=batch,mysql"&gt;link&lt;/a&gt; to create the project. After unzipping the project and loading it in your favorite IDE, you can change the main class, as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint"&gt;package com.example.demo;&#xD;
&#xD;
import java.net.MalformedURLException;&#xD;
&#xD;
import javax.sql.DataSource;&#xD;
&#xD;
import org.springframework.batch.core.Job;&#xD;
import org.springframework.batch.core.configuration.annotation.EnableBatchProcessing;&#xD;
import org.springframework.batch.core.configuration.annotation.JobBuilderFactory;&#xD;
import org.springframework.batch.core.configuration.annotation.StepBuilderFactory;&#xD;
import org.springframework.batch.core.configuration.annotation.StepScope;&#xD;
import org.springframework.batch.item.database.JdbcBatchItemWriter;&#xD;
import org.springframework.batch.item.database.builder.JdbcBatchItemWriterBuilder;&#xD;
import org.springframework.batch.item.file.FlatFileItemReader;&#xD;
import org.springframework.batch.item.file.builder.FlatFileItemReaderBuilder;&#xD;
import org.springframework.beans.factory.annotation.Value;&#xD;
import org.springframework.boot.SpringApplication;&#xD;
import org.springframework.boot.autoconfigure.SpringBootApplication;&#xD;
import org.springframework.context.annotation.Bean;&#xD;
import org.springframework.core.io.Resource;&#xD;
import org.springframework.core.io.UrlResource;&#xD;
&#xD;
@SpringBootApplication&#xD;
@EnableBatchProcessing&#xD;
public class DemoApplication {&#xD;
&#xD;
	public static void main(String[] args) {&#xD;
		System.exit(SpringApplication.exit(&#xD;
			SpringApplication.run(DemoApplication.class, args)));&#xD;
	}&#xD;
	&#xD;
	@Bean&#xD;
	@StepScope&#xD;
	public Resource resource(@Value(&amp;quot;#{jobParameters[&amp;#39;fileName&amp;#39;]}&amp;quot;) String fileName) throws MalformedURLException {&#xD;
		return new UrlResource(fileName);&#xD;
	}&#xD;
&#xD;
	@Bean&#xD;
	public FlatFileItemReader&amp;lt;Person&amp;gt; itemReader(Resource resource)  {&#xD;
		return new FlatFileItemReaderBuilder&amp;lt;Person&amp;gt;()&#xD;
				.name(&amp;quot;personItemReader&amp;quot;)&#xD;
				.resource(resource)&#xD;
				.delimited()&#xD;
				.names(&amp;quot;firstName&amp;quot;, &amp;quot;lastName&amp;quot;)&#xD;
				.targetType(Person.class)&#xD;
				.build();&#xD;
	}&#xD;
&#xD;
	@Bean&#xD;
	public JdbcBatchItemWriter&amp;lt;Person&amp;gt; itemWriter(DataSource dataSource) {&#xD;
		return new JdbcBatchItemWriterBuilder&amp;lt;Person&amp;gt;()&#xD;
				.dataSource(dataSource)&#xD;
				.sql(&amp;quot;INSERT INTO PEOPLE (FIRST_NAME, LAST_NAME) VALUES (:firstName, :lastName)&amp;quot;)&#xD;
				.beanMapped()&#xD;
				.build();&#xD;
	}&#xD;
&#xD;
	@Bean&#xD;
	public Job job(JobBuilderFactory jobs, StepBuilderFactory steps,&#xD;
				   DataSource dataSource, Resource resource) {&#xD;
		return jobs.get(&amp;quot;job&amp;quot;)&#xD;
				.start(steps.get(&amp;quot;step&amp;quot;)&#xD;
						.&amp;lt;Person, Person&amp;gt;chunk(3)&#xD;
						.reader(itemReader(resource))&#xD;
						.writer(itemWriter(dataSource))&#xD;
						.build())&#xD;
				.build();&#xD;
	}&#xD;
&#xD;
	public static class Person {&#xD;
		private String firstName;&#xD;
		private String lastName;&#xD;
                // default constructor + getters/setters omitted for brevity&#xD;
	}&#xD;
&#xD;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;@EnableBatchProcessing&lt;/code&gt; annotation sets up all the infrastructure beans required by Spring Batch (job repository, job launcher, and others) as well as some utilities, such as &lt;code&gt;JobBuilderFactory&lt;/code&gt; and &lt;code&gt;StepBuilderFactory&lt;/code&gt; to facilitate the creation of steps and jobs. In the snippet above, I used those utilities to create a job with a single chunk-oriented step, defined as follows:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;An item reader that reads data from a &lt;code&gt;UrlResource&lt;/code&gt;. In some cloud environments, file systems are read-only or do not even exist, so the ability to stream data without downloading it is almost an essential requirement. Fortunately, Spring Batch has you covered! All file-based item readers (for flat files, XML files, and JSON files) work against the powerful Spring Framework &lt;code&gt;Resource&lt;/code&gt; abstraction, so any implementation of &lt;code&gt;Resource&lt;/code&gt; should work. In this example, I use a &lt;code&gt;UrlResource&lt;/code&gt; to read data directly from the &lt;a href="https://raw.githubusercontent.com/spring-guides/gs-batch-processing/master/initial/src/main/resources/sample-data.csv"&gt;remote URL of sample-data.csv&lt;/a&gt; at GitHub without downloading it. The file name is passed in as a job parameter.&lt;/li&gt;
  &lt;li&gt;An item writer that writes &lt;code&gt;Person&lt;/code&gt; items to the &lt;code&gt;PEOPLE&lt;/code&gt; table in MySQL.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;That&amp;rsquo;s it. Let&amp;rsquo;s package the job and create a docker image for it by using Spring Boot&amp;rsquo;s maven plugin:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint"&gt;$ mvn package&#xD;
...&#xD;
$ mvn spring-boot:build-image -Dspring-boot.build-image.imageName=benas/bootiful-job&#xD;
[INFO] Scanning for projects...&#xD;
[INFO]&#xD;
‚Ä¶&#xD;
[INFO] --- spring-boot-maven-plugin:2.4.1:build-image (default-cli) @ demo ---&#xD;
[INFO] Building image &amp;#39;docker.io/benas/bootiful-job:latest&amp;#39;&#xD;
‚Ä¶&#xD;
[INFO] Successfully built image &amp;#39;docker.io/benas/bootiful-job:latest&amp;#39;&#xD;
[INFO]&#xD;
[INFO] ------------------------------------------------------------------------&#xD;
[INFO] BUILD SUCCESS
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The image should now be correctly built, but let&amp;rsquo;s check that:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint"&gt;$ docker images&#xD;
REPOSITORY             TAG           IMAGE ID               CREATED             SIZE&#xD;
benas/bootiful-job     latest        52244b284f08    41 seconds ago   242MB
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note how Spring Boot created a Docker image without the need to create a Dockerfile! A complete blog post has been written about this awesome feature by the awesome Josh Long: &lt;a href="https://spring.io/blog/2021/01/04/ymnnalft-easy-docker-image-creation-with-the-spring-boot-maven-plugin-and-buildpacks"&gt;YMNNALFT: Easy Docker Image Creation with the Spring Boot Maven Plugin and Buildpacks&lt;/a&gt;. Now let&amp;rsquo;s run this job in a Docker container to check that everything is working as expected:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint"&gt;$ docker run \&#xD;
   -e SPRING_DATASOURCE_URL=jdbc:mysql://192.168.1.53:3306/test \&#xD;
   -e SPRING_DATASOURCE_USERNAME=root \&#xD;
   -e SPRING_DATASOURCE_PASSWORD=root \&#xD;
   -e SPRING_DATASOURCE_DRIVER-CLASS-NAME=com.mysql.cj.jdbc.Driver \&#xD;
   benas/bootiful-job \&#xD;
   fileName=https://raw.githubusercontent.com/benas/spring-batch-lab/master/blog/spring-batch-kubernetes/data/sample1.csv
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You should see something like:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint"&gt;  .   ____          _            __ _ _&#xD;
 /\\ / ___&amp;#39;_ __ _ _(_)_ __  __ _ \ \ \ \&#xD;
( ( )\___ | &amp;#39;_ | &amp;#39;_| | &amp;#39;_ \/ _` | \ \ \ \&#xD;
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )&#xD;
  &amp;#39;  |____| .__|_| |_|_| |_\__, | / / / /&#xD;
 =========|_|==============|___/=/_/_/_/&#xD;
 :: Spring Boot ::                (v2.4.1)&#xD;
&#xD;
2021-01-08 17:03:15.009  INFO 1 --- [           main] com.example.demo.DemoApplication         : Starting DemoApplication v0.0.1-SNAPSHOT using Java 1.8.0_275 on 876da4a1cfe0 with PID 1 (/workspace/BOOT-INF/classes started by cnb in /workspace)&#xD;
2021-01-08 17:03:15.012  INFO 1 --- [           main] com.example.demo.DemoApplication         : No active profile set, falling back to default profiles: default&#xD;
2021-01-08 17:03:15.899  INFO 1 --- [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...&#xD;
2021-01-08 17:03:16.085  INFO 1 --- [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Start completed.&#xD;
2021-01-08 17:03:16.139  INFO 1 --- [           main] o.s.b.c.r.s.JobRepositoryFactoryBean     : No database type set, using meta data indicating: MYSQL&#xD;
2021-01-08 17:03:16.292  INFO 1 --- [           main] o.s.b.c.l.support.SimpleJobLauncher      : No TaskExecutor has been set, defaulting to synchronous executor.&#xD;
2021-01-08 17:03:16.411  INFO 1 --- [           main] com.example.demo.DemoApplication         : Started DemoApplication in 1.754 seconds (JVM running for 2.383)&#xD;
2021-01-08 17:03:16.414  INFO 1 --- [           main] o.s.b.a.b.JobLauncherApplicationRunner   : Running default command line with: [fileName=https://raw.githubusercontent.com/benas/spring-batch-lab/master/blog/spring-batch-kubernetes/data/sample1.csv]&#xD;
2021-01-08 17:03:16.536  INFO 1 --- [           main] o.s.b.c.l.support.SimpleJobLauncher      : Job: [SimpleJob: [name=job]] launched with the following parameters: [{fileName=https://raw.githubusercontent.com/benas/spring-batch-lab/master/blog/spring-batch-kubernetes/data/sample1.csv}]&#xD;
2021-01-08 17:03:16.596  INFO 1 --- [           main] o.s.batch.core.job.SimpleStepHandler     : Executing step: [step]&#xD;
2021-01-08 17:03:17.481  INFO 1 --- [           main] o.s.batch.core.step.AbstractStep         : Step: [step] executed in 884ms&#xD;
2021-01-08 17:03:17.501  INFO 1 --- [           main] o.s.b.c.l.support.SimpleJobLauncher      : Job: [SimpleJob: [name=job]] completed with the following parameters: [{fileName=https://raw.githubusercontent.com/benas/spring-batch-lab/master/blog/spring-batch-kubernetes/data/sample1.csv}] and the following status: [COMPLETED] in 934ms&#xD;
2021-01-08 17:03:17.513  INFO 1 --- [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Shutdown initiated...&#xD;
2021-01-08 17:03:17.534  INFO 1 --- [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Shutdown completed.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The job is now completed, and we can check that data has been successfully loaded in the database:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint"&gt;mysql&amp;gt; select * from PEOPLE;&#xD;
+----+------------+-----------+&#xD;
| ID | FIRST_NAME | LAST_NAME |&#xD;
+----+------------+-----------+&#xD;
|  1 | Jill       | Doe       |&#xD;
|  2 | Joe        | Doe       |&#xD;
|  3 | Justin     | Doe       |&#xD;
|  4 | Jane       | Doe       |&#xD;
|  5 | John       | Doe       |&#xD;
+----+------------+-----------+&#xD;
5 rows in set (0.00 sec)&#xD;

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That&amp;rsquo;s it! Now let&amp;rsquo;s deploy this job on Kubernetes. However, before moving on and deploying this job on Kubernetes, I want to show two things:&lt;/p&gt;&lt;h4&gt;&lt;a href="#preventing-duplicate-job-executions-of-the-same-job-instance" class="anchor" name="preventing-duplicate-job-executions-of-the-same-job-instance"&gt;&lt;/a&gt;Preventing Duplicate Job Executions of the Same Job Instance&lt;/h4&gt;
&lt;p&gt;If you want to see how Spring Batch prevents duplicate job executions, you can try to re-run the job with the same command. The application should fail to start with the following error:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint"&gt;2021-01-08 20:21:20.752 ERROR 1 --- [           main] o.s.boot.SpringApplication               : Application run failed&#xD;
&#xD;
java.lang.IllegalStateException: Failed to execute ApplicationRunner&#xD;
	at org.springframework.boot.SpringApplication.callRunner(SpringApplication.java:798) [spring-boot-2.4.1.jar:2.4.1]&#xD;
	at org.springframework.boot.SpringApplication.callRunners(SpringApplication.java:785) [spring-boot-2.4.1.jar:2.4.1]&#xD;
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:333) [spring-boot-2.4.1.jar:2.4.1]&#xD;
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1309) [spring-boot-2.4.1.jar:2.4.1]&#xD;
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1298) [spring-boot-2.4.1.jar:2.4.1]&#xD;
	at com.example.demo.DemoApplication.main(DemoApplication.java:30) [classes/:0.0.1-SNAPSHOT]&#xD;
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_275]&#xD;
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_275]&#xD;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_275]&#xD;
	at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_275]&#xD;
	at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:49) [workspace/:na]&#xD;
	at org.springframework.boot.loader.Launcher.launch(Launcher.java:107) [workspace/:na]&#xD;
	at org.springframework.boot.loader.Launcher.launch(Launcher.java:58) [workspace/:na]&#xD;
	at org.springframework.boot.loader.JarLauncher.main(JarLauncher.java:88) [workspace/:na]&#xD;
Caused by: org.springframework.batch.core.repository.JobInstanceAlreadyCompleteException: A job instance already exists and is complete for parameters={fileName=https://raw.githubusercontent.com/benas/spring-batch-lab/master/blog/spring-batch-kubernetes/data/sample1.csv}.  If you want to run this job again, change the parameters.&#xD;
‚Ä¶
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Spring Batch does not let the same job instance be re-run after it has successfully completed. This is by design, to prevent duplicate job executions due to either a human error or a platform limitation, as explained in the previous section.&lt;/p&gt;&lt;h4&gt;&lt;a href="#preventing-concurrent-job-executions-of-the-same-job-instance" class="anchor" name="preventing-concurrent-job-executions-of-the-same-job-instance"&gt;&lt;/a&gt;Preventing Concurrent Job Executions of the Same Job Instance&lt;/h4&gt;
&lt;p&gt;In the same spirit, Spring Batch prevents concurrent executions of the same job instance. To test it, add an item processor that does a &lt;code&gt;Thread.sleep&lt;/code&gt; to slow down the processing and try to run a second job execution (in a separate terminal) while the first one is running. The second (concurrent) attempt fails with:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint"&gt;2021-01-08 20:59:04.201 ERROR 1 --- [           main] o.s.boot.SpringApplication               : Application run failed&#xD;
&#xD;
java.lang.IllegalStateException: Failed to execute ApplicationRunner&#xD;
	at org.springframework.boot.SpringApplication.callRunner(SpringApplication.java:798) [spring-boot-2.4.1.jar:2.4.1]&#xD;
	at org.springframework.boot.SpringApplication.callRunners(SpringApplication.java:785) [spring-boot-2.4.1.jar:2.4.1]&#xD;
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:333) [spring-boot-2.4.1.jar:2.4.1]&#xD;
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1309) [spring-boot-2.4.1.jar:2.4.1]&#xD;
	at org.springframework.boot.SpringApplication.run(SpringApplication.java:1298) [spring-boot-2.4.1.jar:2.4.1]&#xD;
	at com.example.demo.DemoApplication.main(DemoApplication.java:31) [classes/:0.0.1-SNAPSHOT]&#xD;
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_275]&#xD;
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_275]&#xD;
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_275]&#xD;
	at java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_275]&#xD;
	at org.springframework.boot.loader.MainMethodRunner.run(MainMethodRunner.java:49) [workspace/:na]&#xD;
	at org.springframework.boot.loader.Launcher.launch(Launcher.java:107) [workspace/:na]&#xD;
	at org.springframework.boot.loader.Launcher.launch(Launcher.java:58) [workspace/:na]&#xD;
	at org.springframework.boot.loader.JarLauncher.main(JarLauncher.java:88) [workspace/:na]&#xD;
Caused by: org.springframework.batch.core.repository.JobExecutionAlreadyRunningException: A job execution for this job is already running: JobExecution: id=1, version=1, startTime=2021-01-08 20:58:46.434, endTime=null, lastUpdated=2021-01-08 20:58:46.435, status=STARTED, exitStatus=exitCode=UNKNOWN;exitDescription=, job=[JobInstance: id=1, version=0, Job=[job]], jobParameters=[{fileName=https://raw.githubusercontent.com/benas/spring-batch-lab/master/blog/spring-batch-kubernetes/data/sample1.csv}]&#xD;
‚Ä¶
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Thanks to the centralized job repository, Spring Batch can detect currently running executions (based on the job status in the database) and prevent concurrent executions either on the same node or any other node of the cluster by throwing a &lt;code&gt;JobExecutionAlreadyRunningException&lt;/code&gt;.&lt;/p&gt;&lt;h3&gt;&lt;a href="#3-deploy-the-job-on-kubernetes" class="anchor" name="3-deploy-the-job-on-kubernetes"&gt;&lt;/a&gt;3. Deploy the Job on Kubernetes&lt;/h3&gt;
&lt;p&gt;Setting up a Kubernetes cluster is beyond the scope of this post, so I assume you already have a Kubernetes cluster up and running and can interact with it by using &lt;code&gt;kubectl&lt;/code&gt;. In this post, I use the single-node local Kubernetes cluster provided by the Docker Desktop application.&lt;/p&gt;
&lt;p&gt;First, I create a service for the external database, as described in &amp;ldquo;Scenario 1: Database outside cluster with IP address&amp;rdquo; from &lt;a href="https://cloud.google.com/blog/products/gcp/kubernetes-best-practices-mapping-external-services"&gt;Kubernetes best practices: mapping external services&lt;/a&gt;. Here is the service definition: &lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint"&gt;kind: Service&#xD;
apiVersion: v1&#xD;
metadata:&#xD;
  name: mysql&#xD;
spec:&#xD;
    type: ClusterIP&#xD;
    ports:&#xD;
      - port: 3306&#xD;
        targetPort: 3306&#xD;
---&#xD;
kind: Endpoints&#xD;
apiVersion: v1&#xD;
metadata:&#xD;
  name: mysql&#xD;
subsets:&#xD;
  - addresses:&#xD;
      - ip: 192.168.1.53 # This is my local IP, you might need to change it if needed&#xD;
    ports:&#xD;
      - port: 3306&#xD;
---&#xD;
apiVersion: v1&#xD;
kind: Secret&#xD;
metadata:&#xD;
  name: db-secret&#xD;
type: Opaque&#xD;
data:&#xD;
  # base64 of &amp;quot;root&amp;quot; ($&amp;gt;echo -n &amp;quot;root&amp;quot; | base64)&#xD;
  db.username: cm9vdA==&#xD;
  db.password: cm9vdA==
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This service can be applied to Kubernetes, as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint"&gt;$ kubectl apply -f src/kubernetes/database-service.yaml
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, since we have already created a Docker image for our job, deploying it to Kubernetes is a matter of defining a &lt;code&gt;Job&lt;/code&gt; resource with the following manifest:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint"&gt;apiVersion: batch/v1&#xD;
kind: Job&#xD;
metadata:&#xD;
  name: bootiful-job-$JOB_NAME&#xD;
spec:&#xD;
  template:&#xD;
    spec:&#xD;
      restartPolicy: OnFailure&#xD;
      containers:&#xD;
        - name: bootiful-job&#xD;
          image: benas/bootiful-job&#xD;
          imagePullPolicy: Never&#xD;
          args: [&amp;quot;fileName=$FILE_NAME&amp;quot;]&#xD;
          env:&#xD;
            - name: SPRING_DATASOURCE_DRIVER-CLASS-NAME&#xD;
              value: com.mysql.cj.jdbc.Driver&#xD;
            - name: SPRING_DATASOURCE_URL&#xD;
              value: jdbc:mysql://mysql/test&#xD;
            - name: SPRING_DATASOURCE_USERNAME&#xD;
              valueFrom:&#xD;
                secretKeyRef:&#xD;
                  name: db-secret&#xD;
                  key: db.username&#xD;
            - name: SPRING_DATASOURCE_PASSWORD&#xD;
              valueFrom:&#xD;
                secretKeyRef:&#xD;
                  name: db-secret&#xD;
                  key: db.password
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This manifest follows the same approach as &lt;a href="https://kubernetes.io/docs/tasks/job/parallel-processing-expansion/"&gt;creating jobs based on a template&lt;/a&gt;, as suggested by Kubernetes docs. This job template serves as a base for creating a job for each input file to ingest. I have already ingested the &lt;code&gt;sample1.csv&lt;/code&gt; file, so I create a job for another remote file named &lt;a href="https://raw.githubusercontent.com/benas/spring-batch-lab/master/blog/spring-batch-kubernetes/data/sample2.csv"&gt;sample2.csv&lt;/a&gt; by using the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint"&gt;$ JOB_NAME=sample2 \&#xD;
  FILE_NAME=&amp;quot;https://raw.githubusercontent.com/benas/spring-batch-lab/master/blog/spring-batch-kubernetes/data/sample2.csv&amp;quot; \&#xD;
  envsubst &amp;lt; src/k8s/job.yaml | kubectl apply -f -
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This command substitutes variables in the job template to create a job definition for the given file and then submits it to Kubernetes. Let&amp;rsquo;s check the job and pod resources in Kubernetes:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint"&gt;$ kubectl get jobs&#xD;
NAME                  COMPLETIONS   DURATION   AGE&#xD;
bootiful-job-sample2   0/1           97s        97s&#xD;
&#xD;
$ kubectl get pods&#xD;
NAME                             READY   STATUS      RESTARTS   AGE&#xD;
bootiful-job-sample2-n8mlb   0/1     Completed   0          7s&#xD;
&#xD;
$ kubectl logs bootiful-job-sample2-n8mlb&#xD;
  .   ____          _            __ _ _&#xD;
 /\\ / ___&amp;#39;_ __ _ _(_)_ __  __ _ \ \ \ \&#xD;
( ( )\___ | &amp;#39;_ | &amp;#39;_| | &amp;#39;_ \/ _` | \ \ \ \&#xD;
 \\/  ___)| |_)| | | | | || (_| |  ) ) ) )&#xD;
  &amp;#39;  |____| .__|_| |_|_| |_\__, | / / / /&#xD;
 =========|_|==============|___/=/_/_/_/&#xD;
 :: Spring Boot ::                (v2.4.1)&#xD;
&#xD;
2021-01-08 17:48:42.053  INFO 1 --- [           main] com.example.demo.BootifulJobApplication  : Starting BootifulJobApplication v0.1 using Java 1.8.0_275 on bootiful-job-person-n8mlb with PID 1 (/workspace/BOOT-INF/classes started by cnb in /workspace)&#xD;
2021-01-08 17:48:42.056  INFO 1 --- [           main] com.example.demo.BootifulJobApplication  : No active profile set, falling back to default profiles: default&#xD;
2021-01-08 17:48:43.028  INFO 1 --- [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...&#xD;
2021-01-08 17:48:43.180  INFO 1 --- [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Start completed.&#xD;
2021-01-08 17:48:43.231  INFO 1 --- [           main] o.s.b.c.r.s.JobRepositoryFactoryBean     : No database type set, using meta data indicating: MYSQL&#xD;
2021-01-08 17:48:43.394  INFO 1 --- [           main] o.s.b.c.l.support.SimpleJobLauncher      : No TaskExecutor has been set, defaulting to synchronous executor.&#xD;
2021-01-08 17:48:43.541  INFO 1 --- [           main] com.example.demo.BootifulJobApplication  : Started BootifulJobApplication in 1.877 seconds (JVM running for 2.338)&#xD;
2021-01-08 17:48:43.544  INFO 1 --- [           main] o.s.b.a.b.JobLauncherApplicationRunner   : Running default command line with: [fileName=https://raw.githubusercontent.com/benas/spring-batch-lab/master/blog/spring-batch-kubernetes/data/sample2.csv]&#xD;
2021-01-08 17:48:43.677  INFO 1 --- [           main] o.s.b.c.l.support.SimpleJobLauncher      : Job: [SimpleJob: [name=job]] launched with the following parameters: [{fileName=https://raw.githubusercontent.com/benas/spring-batch-lab/master/blog/spring-batch-kubernetes/data/sample2.csv}]&#xD;
2021-01-08 17:48:43.758  INFO 1 --- [           main] o.s.batch.core.job.SimpleStepHandler     : Executing step: [step]&#xD;
2021-01-08 17:48:44.632  INFO 1 --- [           main] o.s.batch.core.step.AbstractStep         : Step: [step] executed in 873ms&#xD;
2021-01-08 17:48:44.653  INFO 1 --- [           main] o.s.b.c.l.support.SimpleJobLauncher      : Job: [SimpleJob: [name=job]] completed with the following parameters: [{fileName=https://raw.githubusercontent.com/benas/spring-batch-lab/master/blog/spring-batch-kubernetes/data/sample2.csv}] and the following status: [COMPLETED] in 922ms&#xD;
2021-01-08 17:48:44.662  INFO 1 --- [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Shutdown initiated...&#xD;
2021-01-08 17:48:44.693  INFO 1 --- [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Shutdown completed.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can then check the newly added persons in the &lt;code&gt;PEOPLE&lt;/code&gt; table:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint"&gt;mysql&amp;gt; select * from PEOPLE;&#xD;
+----+------------+-----------+&#xD;
| ID | FIRST_NAME | LAST_NAME |&#xD;
+----+------------+-----------+&#xD;
|  1 | Jill       | Doe       |&#xD;
|  2 | Joe        | Doe       |&#xD;
|  3 | Justin     | Doe       |&#xD;
|  4 | Jane       | Doe       |&#xD;
|  5 | John       | Doe       |&#xD;
|  6 | David      | Doe       |&#xD;
|  7 | Damien     | Doe       |&#xD;
|  8 | Danny      | Doe       |&#xD;
|  9 | Dorothy    | Doe       |&#xD;
|  10 | Daniel    | Doe       |&#xD;
&#xD;
+----+------------+-----------+&#xD;
10 rows in set (0.00 sec)&#xD;

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That&amp;rsquo;s it, our job is successfully running in Kubernetes!&lt;/p&gt;&lt;h2&gt;&lt;a href="#tips-and-tricks" class="anchor" name="tips-and-tricks"&gt;&lt;/a&gt;Tips and Tricks&lt;/h2&gt;
&lt;p&gt;Before concluding this post, I wanted to share some tips and tricks that are worth considering when migrating Spring Batch jobs to the cloud on Kubernetes.&lt;/p&gt;&lt;h3&gt;&lt;a href="#1-job-packaging-and-deployment" class="anchor" name="1-job-packaging-and-deployment"&gt;&lt;/a&gt;1. Job Packaging and Deployment&lt;/h3&gt;
&lt;p&gt;Running more than one Spring Batch job in a single container or pod is not a good idea. This does not follow the cloud-native development best practices and the Unix philosophy in general. Running a job per container or pod has the following advantages:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Separate logs&lt;/li&gt;
  &lt;li&gt;Independent life cycles (bugs, features, deployments, etc)&lt;/li&gt;
  &lt;li&gt;Separate parameters and exit codes&lt;/li&gt;
  &lt;li&gt;Restartability (in case of failure, only restart the failed job)&lt;/li&gt;
&lt;/ul&gt;&lt;h3&gt;&lt;a href="#2-choosing-the-right-spring-batch-job-parameters" class="anchor" name="2-choosing-the-right-spring-batch-job-parameters"&gt;&lt;/a&gt;2. Choosing the Right Spring Batch Job Parameters&lt;/h3&gt;
&lt;p&gt;A successful Spring Batch job instance cannot be restarted. In the same way, a successful Kubernetes job cannot be restarted. This makes designing a Kubernetes job per Spring Batch job instance a perfect match! As a consequence, correctly choosing the identifying job parameters in Spring Batch becomes a crucial task, as doing so determines the identity of job instances and consequently the design of Kubernetes jobs (See point 3). Two important aspects of the framework are affected by this choice:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Job identification: Spring Batch prevents duplicate and concurrent job executions based on the identity of the job instance.&lt;/li&gt;
  &lt;li&gt;Failure scenario: Spring Batch relies on the job instance&amp;rsquo;s identity to start a new job execution where the previous one left off.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Batch processing is about processing &lt;strong&gt;fixed, immutable&lt;/strong&gt; data sets. If the input data is not fixed, then a stream-processing tool is more appropriate. Identifying job parameters in Spring Batch should represent a &lt;strong&gt;uniquely identifiable immutable&lt;/strong&gt; data set. A good hint to correctly choose a set of identifying job parameters is calculating their hash (or more precisely the hash of the data they represent) and making sure that that hash is stable. Here are some examples:&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Job parameters &lt;/th&gt;
      &lt;th align="center"&gt;Good/Bad &lt;/th&gt;
      &lt;th align="right"&gt;Comments &lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;fileName=log.txt &lt;/td&gt;
      &lt;td align="center"&gt;Bad &lt;/td&gt;
      &lt;td align="right"&gt;An ever growing log file is not a fixed data set &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;fileName=transactions-2020-08-20.csv &lt;/td&gt;
      &lt;td align="center"&gt;Good &lt;/td&gt;
      &lt;td align="right"&gt;As long as the file content is fixed &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;folderName=/in/data &lt;/td&gt;
      &lt;td align="center"&gt;Bad &lt;/td&gt;
      &lt;td align="right"&gt;A folder with a variable content is not a fixed data set &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;folderName=/in/data/2020/12/20 &lt;/td&gt;
      &lt;td align="center"&gt;Good &lt;/td&gt;
      &lt;td align="right"&gt;A folder with the files of all orders received on a given day &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;jmsQueueName=events &lt;/td&gt;
      &lt;td align="center"&gt;Bad &lt;/td&gt;
      &lt;td align="right"&gt;Items are removed from the queue so this is not a fixed data set &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;orderDate=2020-08-20 &lt;/td&gt;
      &lt;td align="center"&gt;Good &lt;/td&gt;
      &lt;td align="right"&gt;If used, for example, in a database select query on D+1 &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Unfortunately, many people fail at designing good identifying job parameters and end up adding a timestamp or a random number as an additional identifying job parameter acting as job instance discriminator. Using an ever growing ‚Äúrun.id‚Äù parameter is a symptom of such a failure.&lt;/p&gt;&lt;h3&gt;&lt;a href="#3-choosing-the-right-kubernetes-job-deployment-pattern" class="anchor" name="3-choosing-the-right-kubernetes-job-deployment-pattern"&gt;&lt;/a&gt;3. Choosing the Right Kubernetes Job Deployment Pattern&lt;/h3&gt;
&lt;p&gt;The Kubernetes&amp;rsquo; documentation provides a whole section called &lt;a href="https://kubernetes.io/docs/concepts/workloads/controllers/job/#job-patterns"&gt;Job patterns&lt;/a&gt;, which describes how to choose the right job deployment pattern. In this post, I followed the &lt;a href="https://kubernetes.io/docs/tasks/job/parallel-processing-expansion/"&gt;Parallel processing using expansions&lt;/a&gt; approach to create a job per file from a template. While this approach allows for processing multiple files in parallel, it can put a pressure on Kubernetes when there are many files to ingest, as this would result in many Kubernetes job objects being created. If all your files have a similar structure and you want to create a single job to ingest them in one shot, you can use the &lt;code&gt;MultiResourceItemReader&lt;/code&gt; provided by Spring Batch and create a single Kubernetes job. Another option is to use a single job with a partitioned step where each worker step handles a file (this can be achieved by using the built-in &lt;code&gt;MultiResourcePartitioner&lt;/code&gt;).&lt;/p&gt;&lt;h3&gt;&lt;a href="#4-graceful-abrupt-shutdown-implication" class="anchor" name="4-graceful-abrupt-shutdown-implication"&gt;&lt;/a&gt;4. Graceful/Abrupt Shutdown Implication&lt;/h3&gt;
&lt;p&gt;When a Spring Batch job execution fails, you can restart it if the job instance is restartable. You can automate this, as long as the job execution is shut down gracefully, since this gives Spring Batch a chance to correctly set the job execution&amp;rsquo;s status to &lt;code&gt;FAILED&lt;/code&gt; and set its &lt;code&gt;END_TIME&lt;/code&gt; to a non-null value. However, if the job execution fails abruptly, the job execution&amp;rsquo;s status is still be set to &lt;code&gt;STARTED&lt;/code&gt; and its &lt;code&gt;END_TIME&lt;/code&gt; is &lt;code&gt;null&lt;/code&gt;. When you try to restart such a job execution, Spring Batch will think (since it only looks at the database status) that a job execution is currently running for this instance and fails with a &lt;code&gt;JobExecutionAlreadyRunningException&lt;/code&gt;. In such cases, the metadata tables should be updated to allow the restart of such a failed execution &amp;ndash; something like:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint"&gt;&amp;gt; update BATCH_JOB_EXECUTION set status = &amp;#39;FAILED&amp;#39;, END_TIME = &amp;#39;2020-01-15 10:10:28.235&amp;#39; where job_execution_id = X;&#xD;
&amp;gt; update BATCH_STEP_EXECUTION set status = &amp;#39;FAILED&amp;#39; where job_execution_id = X and step_name=&amp;#39;failed step name&amp;#39;;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Graceful/Abrupt shutdown of Spring Batch jobs is directly related to Kubernetes jobs restart policy. For example, with &lt;code&gt;restartPolicy=OnFailure&lt;/code&gt;, when a pod fails abruptly and the job controller creates a new pod immediately after, you cannot update the database in a timely manner and the new Spring Batch job execution fails with a &lt;code&gt;JobExecutionAlreadyRunningException&lt;/code&gt;. The same happens with the third pod and so on, until the pod reaches the &lt;code&gt;CrashLoopBackOff&lt;/code&gt; state and gets deleted once the &lt;code&gt;backoffLimit&lt;/code&gt; is exceeded.&lt;/p&gt;
&lt;p&gt;Now, if you follow the best practice of running your Spring Boot Batch application with &lt;code&gt;System.exit(SpringApplication.exit(SpringApplication.run(MyBatchApplication.class, args)));&lt;/code&gt; as shown in the snippet above, Spring Boot (and, in turn, Spring Batch) can correctly handle &lt;code&gt;SIGTERM&lt;/code&gt; signals and gracefully shutdown your application when Kubernetes starts the &lt;a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#pod-termination"&gt;pod termination process&lt;/a&gt;. With this in place, when pods are gracefully shutdown, the Spring Batch job instance can automatically restart until completion. Unfortunately, graceful shutdown of Kubernetes pods is not guaranteed, and you should take this into consideration when you set the restart policy and the &lt;code&gt;backoffLimit&lt;/code&gt; values, to ensure you have enough time to update the job repository as needed for failed jobs.&lt;/p&gt;
&lt;p&gt;It should be noted that the &lt;code&gt;shell&lt;/code&gt; form of docker&amp;rsquo;s &lt;code&gt;ENTRYPOINT&lt;/code&gt; &lt;a href="https://docs.docker.com/engine/reference/builder/#entrypoint"&gt;does not send Unix signals to the sub-process running in the container&lt;/a&gt;. So in order to correctly intercept Unix signals by the Spring Batch job running in a container, the &lt;code&gt;ENTRYPOINT&lt;/code&gt; form should be &lt;code&gt;exec&lt;/code&gt;. This is also directly related to Kubernetes&amp;rsquo; pod termination process mentioned above. More details about this matter can be found in the &lt;a href="https://cloud.google.com/blog/products/gcp/kubernetes-best-practices-terminating-with-grace"&gt;Kubernetes best practices: terminating with grace&lt;/a&gt; blog post.&lt;/p&gt;&lt;h3&gt;&lt;a href="#5-choosing-the-right-kubernetes-job-concurrency-policy" class="anchor" name="5-choosing-the-right-kubernetes-job-concurrency-policy"&gt;&lt;/a&gt;5. Choosing the Right Kubernetes Job Concurrency Policy&lt;/h3&gt;
&lt;p&gt;As I pointed out earlier, Spring Batch prevents concurrent job executions of the same job instance. So, if you follow the &amp;ldquo;Kubernetes job per Spring Batch job instance&amp;rdquo; deployment pattern, setting the job&amp;rsquo;s &lt;code&gt;spec.parallelism&lt;/code&gt; to a value higher than 1 does not make sense, as this starts two pods in parallel and one of them will certainly fail with a &lt;code&gt;JobExecutionAlreadyRunningException&lt;/code&gt;. However, setting a &lt;code&gt;spec.parallelism&lt;/code&gt; to a value higher than 1 makes perfect sense for a partitioned job. In this case, partitions can be executed in parallel pods. Correctly choosing the concurrency policy is tightly related to which job pattern is chosen (As explained in point 3).&lt;/p&gt;&lt;h3&gt;&lt;a href="#6-job-metadata-housekeeping" class="anchor" name="6-job-metadata-housekeeping"&gt;&lt;/a&gt;6. Job Metadata Housekeeping&lt;/h3&gt;
&lt;p&gt;Deleting a Kubernetes job deletes its corresponding pods. Kubernetes provides a way to automatically clean up completed jobs by using the &lt;code&gt;ttlSecondsAfterFinished&lt;/code&gt; parameter. However, there is no equivalent to this in Spring Batch: You should clean up the job repository manually. You should take this into consideration for any serious production batch infrastructure, as job instances and executions can grow very quickly, depending on the frequency and number of deployed jobs. I see a good opportunity here to create a Kubernetes Custom Resource Definition that deletes Spring Batch&amp;rsquo;s metadata when the corresponding Kubernetes job is deleted.&lt;/p&gt;&lt;h2&gt;&lt;a href="#conclusion" class="anchor" name="conclusion"&gt;&lt;/a&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;I hope this post has shed some light on the challenges of designing, developing, and running batch applications in the cloud and how Spring Batch, Spring Boot and Kubernetes can tremendously simplify this task. This post showed how to go from &lt;a href="https://start.spring.io"&gt;start.spring.io&lt;/a&gt; to Kubernetes in three simple steps, thanks to the productivity of the Spring ecosystem, but this is only scratching the surface of the matter. This post is the first part of a blog series in which I will cover other aspects of running Spring Batch jobs on Kubernetes. In the next posts, I will tackle job observability with &lt;a href="https://micrometer.io"&gt;Micrometer&lt;/a&gt; and &lt;a href="https://tanzu.vmware.com/observability"&gt;Wavefront&lt;/a&gt; and then how to scale Spring Batch jobs on Kubernetes. Stay tuned!&lt;/p&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>YMNNALFT:  The Spring *Utils Classes</title>
    <link rel="alternate" href="https://spring.io/blog/2021/01/27/ymnnalft-the-spring-utils-classes" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>Josh Long</name>
    </author>
    <id>tag:spring.io,2020-12-30:4323</id>
    <updated>2021-01-27T11:00:00Z</updated>
    <content type="html">&lt;p&gt;Welcome to another installment of &lt;em&gt;You May Not Need Another Library For That&lt;/em&gt; (YMNNALFT)! I&amp;rsquo;ve spent a lot of time since 2016 illuminating (or trying to, anyway!) some of the more enormous opportunities in the Spring ecosystem in &lt;a href="http://bit.ly/spring-tips-playlist"&gt;my Spring Tips videos&lt;/a&gt;. Today, however, I come to you in a different spirit, wanting to focus on the little, sometimes hidden, gems that do fantastic things and that might spare you an additional third-party dependency and its implied complexity. &lt;/p&gt;
&lt;p&gt;We&amp;rsquo;ve all been there. There&amp;rsquo;s some everyday string-manipulation routine you want, so you extract it out into a separate abstract class and expose it as a &lt;code&gt;static&lt;/code&gt; method. Then, there&amp;rsquo;s some factory method for building a &lt;code&gt;java.util.Collection&amp;lt;T&amp;gt;&lt;/code&gt;, so you extract it out into a separate class and expose it as a &lt;code&gt;static&lt;/code&gt; method. And eventually, you&amp;rsquo;ve got a whole collection of these things scoured about your codebase, and there&amp;rsquo;s little to no cohesion across them. After all, there&amp;rsquo;s just not that much to it, right? These are, essentially, only global functions, not really methods on stateful objects, &lt;em&gt;per se&lt;/em&gt;. &lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s not to say that building your own static methods is inherently wrong, as long as you approach them with some conventions. We typically use abstract classes with static methods, for example.&lt;/p&gt;
&lt;p&gt;It all starts off so innocuously. Of course, it does. You know the cycle. First, a few methods in a solitary class stuck in a jar in a company-wide artifact repository. Then there are classes, plural. Now &lt;em&gt;packages&lt;/em&gt; have entered the picture. Packages are trouble! You&amp;rsquo;ll start to realize that some thought had better go into an organization, or things will quickly get out of hand. You start accepting pull requests. At some point, there are breaking changes, and developers with pitchforks line up outside your door. You wonder why everyone keeps eating slashing your tires at work. It&amp;rsquo;s too much! So you get the company to open-source your nascent module. It&amp;rsquo;s the &lt;em&gt;world&lt;/em&gt;&amp;rsquo;s problem now! Like Tamagotchis and reality TV, there can be no end. And that wide world? Well, that wide world &lt;em&gt;loves&lt;/em&gt; breaking changes in point-releases, and they will &lt;em&gt;love you&lt;/em&gt; for them! &lt;/p&gt;
&lt;p&gt;Maybe.&lt;/p&gt;
&lt;p&gt;There is another way. &lt;/p&gt;
&lt;p&gt;There are many third-party utility libraries of varying quality out there: GS Collections, Apache Commons, Guava, etc. There is no shortage of options here. Did you know Spring offers several utility classes in the frameworks themselves, potentially sparing you a dependency? I&amp;rsquo;m not saying that they&amp;rsquo;ll do everything you might get from the distinguished competition, but you might be surprised! This example will look at a handful of these utility classes, but there are many others on the classpath. You can typically find them by going into your IDE and searching for &lt;code&gt;*Utils&lt;/code&gt; in your class search or &lt;code&gt;*Utils.java&lt;/code&gt; in your file search. Let&amp;rsquo;s take a look at some of them.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Many of these are included by default in every Spring Boot project through the following transitive (or default) dependency on &lt;a href="http://start.spring.io"&gt;the Spring Initializr&lt;/a&gt; - &lt;code&gt;org.springframework.boot&lt;/code&gt; : &lt;code&gt;spring-boot-starter&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here&amp;rsquo;s the code:&lt;/p&gt;
&lt;pre&gt;&lt;code class="prettyprint java"&gt;package bootiful.utils;&#xD;
&#xD;
import lombok.AllArgsConstructor;&#xD;
import lombok.Data;&#xD;
import lombok.extern.log4j.Log4j2;&#xD;
import org.springframework.aop.support.AopUtils;&#xD;
import org.springframework.beans.BeanUtils;&#xD;
import org.springframework.boot.SpringApplication;&#xD;
import org.springframework.boot.autoconfigure.SpringBootApplication;&#xD;
import org.springframework.boot.context.event.ApplicationReadyEvent;&#xD;
import org.springframework.context.ApplicationListener;&#xD;
import org.springframework.context.annotation.Bean;&#xD;
import org.springframework.core.ResolvableType;&#xD;
import org.springframework.core.io.ClassPathResource;&#xD;
import org.springframework.core.io.Resource;&#xD;
import org.springframework.jmx.support.JmxUtils;&#xD;
import org.springframework.stereotype.Component;&#xD;
import org.springframework.util.*;&#xD;
&#xD;
import javax.annotation.PostConstruct;&#xD;
import java.beans.PropertyDescriptor;&#xD;
import java.io.InputStreamReader;&#xD;
import java.io.Reader;&#xD;
import java.io.Serializable;&#xD;
import java.lang.reflect.Constructor;&#xD;
import java.lang.reflect.Field;&#xD;
import java.util.*;&#xD;
&#xD;
@Log4j2&#xD;
@SpringBootApplication&#xD;
public class BootifulApplication {&#xD;
&#xD;
	@Data&#xD;
	@AllArgsConstructor&#xD;
	@Component&#xD;
	public static class DemoClass {&#xD;
&#xD;
		@PostConstruct&#xD;
		public void begin() {&#xD;
			log.info(&amp;quot;begin()&amp;quot;);&#xD;
		}&#xD;
&#xD;
		private final List&amp;lt;Map&amp;lt;String, Object&amp;gt;&amp;gt; list = new ArrayList&amp;lt;&amp;gt;();&#xD;
&#xD;
	}&#xD;
&#xD;
	@Bean&#xD;
	ApplicationListener&amp;lt;ApplicationReadyEvent&amp;gt; ready(DemoClass demo) {&#xD;
		return event -&amp;gt; {&#xD;
&#xD;
			Assert.notNull(demo.getList(), &amp;quot;the list can&amp;#39;t be null&amp;quot;);&#xD;
&#xD;
			beansUtils(demo);&#xD;
			classUtils();&#xD;
			systemPropertyUtils();&#xD;
			fileCopyUtils();&#xD;
			aop(demo);&#xD;
			reflection();&#xD;
			ensure();&#xD;
			collections();&#xD;
			serialize();&#xD;
&#xD;
		};&#xD;
	}&#xD;
&#xD;
	private void ensure() {&#xD;
		int counter = 2;&#xD;
		Assert.state(counter == 2, () -&amp;gt; &amp;quot;the counter should be 2 or more. Was &amp;quot; + counter);&#xD;
		Assert.hasText(&amp;quot;Hello, world!&amp;quot;, () -&amp;gt; &amp;quot;this string should be a non-null, non-empty String&amp;quot;);&#xD;
	}&#xD;
&#xD;
	private void reflection() {&#xD;
&#xD;
		ReflectionUtils.doWithFields(DemoClass.class, field -&amp;gt; log.info(&amp;quot;field = &amp;quot; + field.toString()));&#xD;
		ReflectionUtils.doWithMethods(DemoClass.class, method -&amp;gt; log.info(&amp;quot;method = &amp;quot; + method.toString()));&#xD;
&#xD;
		Field list = ReflectionUtils.findField(DemoClass.class, &amp;quot;list&amp;quot;);&#xD;
		log.info(Objects.requireNonNull(list).toString());&#xD;
&#xD;
		ResolvableType rt = ResolvableType.forField(list);&#xD;
		log.info(rt.toString());&#xD;
	}&#xD;
&#xD;
	private void aop(DemoClass demoClass) {&#xD;
		Class&amp;lt;?&amp;gt; targetClass = AopUtils.getTargetClass(demoClass);&#xD;
		log.info(&amp;quot;Class&amp;lt;?&amp;gt; is &amp;quot; + targetClass);&#xD;
		log.info(&amp;quot;is AOP proxy? &amp;quot; + AopUtils.isAopProxy(demoClass));&#xD;
		log.info(&amp;quot;is CGlib proxy? &amp;quot; + AopUtils.isCglibProxy(demoClass));&#xD;
	}&#xD;
&#xD;
	private void collections() {&#xD;
		Collection&amp;lt;String&amp;gt; names = Arrays.asList(&amp;quot;Tammie&amp;quot;, &amp;quot;Kimly&amp;quot;, &amp;quot;Josh&amp;quot;);&#xD;
		boolean contains = CollectionUtils.containsAny(names, Arrays.asList(&amp;quot;Josh&amp;quot;));&#xD;
		Assert.state(contains, () -&amp;gt; &amp;quot;one or more of the names in &amp;quot; + names.toString() + &amp;quot; should be present&amp;quot;);&#xD;
	}&#xD;
&#xD;
	private void serialize() {&#xD;
		Customer in = new Customer(593232329, &amp;quot;Josh&amp;quot;);&#xD;
		byte[] bytes = SerializationUtils.serialize(in);&#xD;
		Customer out = (Customer) SerializationUtils.deserialize(bytes);&#xD;
		Assert.state(out.getId() == in.getId() &amp;amp;&amp;amp; out.getName().equals(in.getName()),&#xD;
				() -&amp;gt; &amp;quot;the &amp;quot; + Customer.class.getName() + &amp;quot; did not serialize correctlyy&amp;quot;);&#xD;
	}&#xD;
&#xD;
	private void fileCopyUtils() {&#xD;
		Resource cpr = new ClassPathResource(&amp;quot;/application.properties&amp;quot;);&#xD;
		try (Reader r = new InputStreamReader(cpr.getInputStream())) {&#xD;
			String contents = FileCopyUtils.copyToString(r);&#xD;
			log.info(&amp;quot;application.properties contents: &amp;quot; + contents);&#xD;
		}&#xD;
		catch (Exception e) {&#xD;
			throw new RuntimeException(e);&#xD;
		}&#xD;
	}&#xD;
&#xD;
	private void systemPropertyUtils() {&#xD;
		String resolvedText = SystemPropertyUtils.resolvePlaceholders(&amp;quot;my home directory is ${user.home}&amp;quot;);&#xD;
		log.info(&amp;quot;resolved text: &amp;quot; + resolvedText);&#xD;
	}&#xD;
&#xD;
	private void classUtils() {&#xD;
		Constructor&amp;lt;DemoClass&amp;gt; demoClassConstructor = ClassUtils.getConstructorIfAvailable(DemoClass.class);&#xD;
		log.info(&amp;quot;demoClassConstructor: &amp;quot; + demoClassConstructor);&#xD;
		try {&#xD;
			DemoClass demoClass = demoClassConstructor.newInstance();&#xD;
			log.info(&amp;quot;newInstance&amp;#39;d demoClass: &amp;quot; + demoClass);&#xD;
		}&#xD;
		catch (Exception e) {&#xD;
			throw new RuntimeException(e);&#xD;
		}&#xD;
	}&#xD;
&#xD;
	private void beansUtils(DemoClass demo) {&#xD;
		PropertyDescriptor[] descriptors = BeanUtils.getPropertyDescriptors(demo.getClass());&#xD;
		for (PropertyDescriptor pd : descriptors) {&#xD;
			log.info(&amp;quot;pd: &amp;quot; + pd.getName());&#xD;
		}&#xD;
	}&#xD;
&#xD;
	public static void main(String[] args) {&#xD;
		SpringApplication.run(BootifulApplication.class, args);&#xD;
	}&#xD;
&#xD;
}&#xD;
&#xD;
@Data&#xD;
class Customer implements Serializable {&#xD;
&#xD;
	static final long serialVersionUID = 1L;&#xD;
&#xD;
	private int id;&#xD;
&#xD;
	private String name;&#xD;
&#xD;
	public Customer(int id, String name) {&#xD;
		this.id = id;&#xD;
		this.name = name;&#xD;
	}&#xD;
&#xD;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This example introduces a &lt;em&gt;sm√∂rg√•sbord&lt;/em&gt; of various &lt;code&gt;Utils&lt;/code&gt; class implementations in the Spring ecosystem. It looks at &lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code&gt;BeanUtils&lt;/code&gt; - useful functions for dealing with JavaBeans&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;ClassUtils&lt;/code&gt; - useful functions for asking questions reflectively about types&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;SystemPropertyUtils&lt;/code&gt; - useful functions for dealing with &lt;code&gt;System&lt;/code&gt; properties&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;FileCopyUtils&lt;/code&gt; - useful functions for copying &lt;code&gt;InputStream&lt;/code&gt; and &lt;code&gt;OutputStream&lt;/code&gt; implementations&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;AopUtils&lt;/code&gt; - useful functions for dealing with Spring&amp;rsquo;s AOP proxies&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;ReflectionUtils&lt;/code&gt; - useful functions for dealing with reflection, broadly&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;Assert&lt;/code&gt; - useful functions to help with design-by-contract-style assertions&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;CollectionUtils&lt;/code&gt; - useful functions for working various Java &lt;code&gt;java.util.Collection&lt;/code&gt; types&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;SerializeUtils&lt;/code&gt; - useful functions for working with Java serialization&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There&amp;rsquo;s a &lt;em&gt;ton&lt;/em&gt; of exciting stuff, and this dense example doesn&amp;rsquo;t even begin to scratch the surface! &lt;/p&gt;
&lt;p&gt;Did you like this gem at a glance approach? Did you learn anything? As always, I&amp;rsquo;m keen on hearing from you, so &lt;a href="http://twitter.com/starbuxman"&gt;please sound off on Twitter (@starbuxman) &lt;/a&gt;! I&amp;rsquo;ll be back with another installment of &lt;em&gt;YMNNALFT&lt;/em&gt;, so be sure not to miss that. &lt;/p&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
  <entry>
    <title>This Week in Spring - January 26th, 2021</title>
    <link rel="alternate" href="https://spring.io/blog/2021/01/26/this-week-in-spring-january-26th-2021" />
    <category term="engineering" label="Engineering" />
    <author>
      <name>Josh Long</name>
    </author>
    <id>tag:spring.io,2021-01-26:4347</id>
    <updated>2021-01-26T21:50:00Z</updated>
    <content type="html">&lt;p&gt;Hi, Spring fans! Welcome to another installment of &lt;em&gt;This Week in Spring&lt;/em&gt;! As I type this I&amp;rsquo;m sitting on the amazing Tanzu Tuesday&amp;rsquo;s stream as a (guest) cohost &lt;a href="http://twitter.com/tiffanyfayj"&gt;with Tiffany Jernigan (@tiffanyfayj)&lt;/a&gt; learning about tips and tricks for working with Spring Boot and Kubernetes from the &lt;a href="http://twitter.com/olliehughes82"&gt;Spring team&amp;rsquo;s Oliver Hughes (@olliehughes82)&lt;/a&gt;. If you missed it, then it - and all sorts of other content - is available for replays on our &lt;a href="http://twitch.tv/vmwaretanzu"&gt;Tanzu Twitch.tv channel&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Now then, we&amp;rsquo;ve got a ton of good stuff to get to so let&amp;rsquo;s gooo&amp;hellip;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Tomorrow, I&amp;rsquo;ll be streaming with Reactor team member and &lt;a href="https://tanzu.vmware.com/developer/tv/code/0018/"&gt;RSocket committer Oleh Dokuka on Twitch.tv/vmwaretanzu&lt;/a&gt; - don&amp;rsquo;t miss it!&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://twitter.com/springcloud/status/1352347656178302997"&gt;Mark your calendars! Call for Papers and registration for SpringOne 2021 open on Feb. 16. Sign up for updates&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2021/01/21/a-bootiful-podcast-spring-tools-lead-martin-lippert-on-sustainable-software"&gt;A Bootiful Podcast - Spring Tools lead Martin Lippert on sustainable software&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2021/01/21/bootiful-application-monitoring-with-azure-spring-cloud"&gt;Bootiful Application Monitoring with Azure Spring Cloud&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://twitter.com/JavaAtMicrosoft/status/1352321956138217474"&gt;You can monitor Azure Spring Cloud Spring Boot apps and dependencies without any effort! Brought to you jointly by Microsoft and VMware &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2021/01/20/ymnnalft-dimensional-metrics-accumulation-with-micrometer"&gt;YMNNALFT: Dimensional Metrics Accumulation with Micrometer&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=j6Y-K0J7HD4&amp;feature=share"&gt;Building a Spring Boot and Spring MVC web application&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://developer.okta.com/blog/2021/01/20/reactive-java-microservices"&gt;The Okta blog has a nice post on reactive Java microservices &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://github.com/trankchung/kubeswitch/"&gt;Kubeswitch v0.2.0 - Kubernetes context and namespace switching&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://www.javavogue.com/2019/02/how-to-create-a-rest-api-with-spring-boot/"&gt;How to create a REST API with Spring Boot&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://jishuin.proginn.com/p/763bfbd382bf"&gt;An interesting post on RSocket (Êõø‰ª£ REST ÁöÑ‰∏ç‰∫åÈÄâÊã©)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://spring.io/blog/2021/01/21/spring-boot-2-5-0-m1-available-now"&gt;Spring Boot 2.5.0-M1 available now&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://twitter.com/rorypreddy/status/1353338898219479044?s=12"&gt;The Azure Spring Cloud VSCode extension is out!&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;I really enjoyed this discussion - &lt;a href="https://www.reddit.com/r/kubernetes/comments/l2l9jf/top_considerations_when_evaluating_an_ingress/"&gt;Top Considerations when Evaluating an Ingress Controller for Kubernetes&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://twitter.com/VMwareTanzu/status/1351951632158875652"&gt;VMwareTanzu KubeAcademy‚Äôs expert instructors design and deliver each course to give you practical #Kubernetes training. &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href="https://twitter.com/cloudfoundry/status/1351963315614879746"&gt; Learn how CF Protect helps recover data in Cloud Foundry &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- rendered by Sagan Renderer Service --&gt;</content>
  </entry>
</feed>
